{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 머신러닝\n",
    "## 텍스트 데이터\n",
    "---\n",
    "# IMDb 리뷰 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전체 :  말뭉치 (corpus)\n",
    "- 샘플 하나 : 문서 (document)\n",
    "- 자연어 처리 : NLP(Natural language processing)\n",
    "- 한국어는 하나의 **어절**이 여러 개의 의미 단위로 구성되는 경우가 있으므로 **형태소 분석**을 해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDb 영화 리뷰 데이터셋 : https://github.com/rickiepark/introduction_to_ml_with_python/blob/master/data/aclImdb_v1.tar.gz\n",
    "- 압축을 풀어 data/aclImdb 폴더로 옮긴다\n",
    "> ```\n",
    "./data\n",
    "./data/aclImdb\n",
    "./data/aclImdb/test\n",
    "./data/aclImdb/test/pos\n",
    "./data/aclImdb/test/neg\n",
    "./data/aclImdb/train\n",
    "./data/aclImdb/train/pos\n",
    "./data/aclImdb/train/neg\n",
    "./data/aclImdb/train/unsup\n",
    "```\n",
    "\n",
    "- ./data/aclImdb/train/unsup 폴더를 ./data/aclImdb/train_unsup 폴더로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "imdb_train = load_files('data/aclImdb/train/')\n",
    "imdb_test = load_files('data/aclImdb/test/')\n",
    "\n",
    "np.save('imdb.npy',[imdb_train, imdb_test])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imdb_train, imdb_test = np.load('imdb.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imdb_train 과 imdb_test 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['data/aclImdb/train/pos\\\\11485_10.txt',\n",
       "       'data/aclImdb/train/neg\\\\6802_1.txt',\n",
       "       'data/aclImdb/train/pos\\\\7641_10.txt', ...,\n",
       "       'data/aclImdb/train/neg\\\\7611_4.txt',\n",
       "       'data/aclImdb/train/neg\\\\8470_2.txt',\n",
       "       'data/aclImdb/train/neg\\\\1245_2.txt'], dtype='<U35')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DESCR, data, filenames, target, target_names\n",
    "display(type(imdb_train.data), len(imdb_train.data))     # list\n",
    "display(imdb_train.filenames)\n",
    "display(type(imdb_train.target), len(imdb_train.target)) # array\n",
    "display(imdb_train.target_names)                         # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.target[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.data[0].decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 문장은 타입이 bytes 이다. 그리고 문장 중간에 ```'<br />'``` 이 포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = imdb_train.data[6]\n",
    "s.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = imdb_train.data[6]\n",
    "s.decode().replace('<br />', '') # s.replace(b'<br />', b'') 로 변환하면 출력 타입이 bytes 이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = [s.decode().replace('<br />', '') for s in imdb_train.data]\n",
    "len(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = imdb_train.target\n",
    "display(y_train.shape, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load_files() 함수는 폴더 이름을 알파벳 순서로 읽기 때문에, 'neg' 폴더는 0, 'pos' 폴더는 1 로 타겟값이 지정된다.\n",
    "- imdb_train.target_names 값의 순서이기도 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 파일을 분석하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['data/aclImdb/test/pos\\\\11485_9.txt',\n",
       "       'data/aclImdb/test/neg\\\\6802_1.txt',\n",
       "       'data/aclImdb/test/pos\\\\7641_8.txt', ...,\n",
       "       'data/aclImdb/test/neg\\\\7611_2.txt',\n",
       "       'data/aclImdb/test/neg\\\\8470_1.txt',\n",
       "       'data/aclImdb/test/neg\\\\1245_2.txt'], dtype='<U34')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(type(imdb_test.data), len(imdb_test.data))     # list\n",
    "display(imdb_test.filenames)\n",
    "display(type(imdb_test.target), len(imdb_test.target)) # array\n",
    "display(imdb_test.target_names)                         # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_test = [s.decode().replace('<br />', '') for s in imdb_test.data]\n",
    "display(len(text_test))\n",
    "\n",
    "y_test = imdb_test.target\n",
    "display(y_test.shape, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **정리**\n",
    "> - text_train => list, 25000\n",
    "> - y_train => array, 25000\n",
    "> - text_test => list, 25000\n",
    "> - y_test => array, 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW (Bag Of Words) : 단어집\n",
    "전체 텍스트 데이터에서 단어집을 만드는 방법\n",
    "- CountVectorizer\n",
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ss = ['I am Tom. Tom is me!', 'He is Tom. He is a man.']\n",
    "vect = CountVectorizer()\n",
    "vect.fit(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'tom': 5, 'is': 2, 'me': 4, 'he': 1, 'man': 3}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_ # 한 글자 단어와 구두점은 제외한다 (소문자로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'am'), (1, 'he'), (2, 'is'), (3, 'man'), (4, 'me'), (5, 'tom')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voca = vect.vocabulary_\n",
    "sorted([(v,k) for k,v in voca.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 2],\n",
       "       [0, 2, 2, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(ss).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB 데이터의 BOW 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(text_train) # 단어집이 만들어진다\n",
    "X_train = vect.transform(text_train) # sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 75911)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vect.vocabulary_), len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75911 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3431163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 75911)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero': 75669,\n",
       " 'day': 16986,\n",
       " 'leads': 38653,\n",
       " 'you': 75381,\n",
       " 'to': 68091,\n",
       " 'think': 67468,\n",
       " 'even': 23059,\n",
       " 're': 54503,\n",
       " 'why': 73998,\n",
       " 'two': 69757,\n",
       " 'boys': 8922,\n",
       " 'young': 75392,\n",
       " 'men': 42764,\n",
       " 'would': 74762,\n",
       " 'do': 19634,\n",
       " 'what': 73731,\n",
       " 'they': 67409,\n",
       " 'did': 18588,\n",
       " 'commit': 13888,\n",
       " 'mutual': 45268,\n",
       " 'suicide': 65104,\n",
       " 'via': 72211,\n",
       " 'slaughtering': 61588,\n",
       " 'their': 67280,\n",
       " 'classmates': 12958,\n",
       " 'it': 35211,\n",
       " 'captures': 10809,\n",
       " 'must': 45209,\n",
       " 'be': 6512,\n",
       " 'beyond': 7341,\n",
       " 'bizarre': 7716,\n",
       " 'mode': 43993,\n",
       " 'of': 47352,\n",
       " 'being': 6852,\n",
       " 'for': 25839,\n",
       " 'humans': 32540,\n",
       " 'who': 73935,\n",
       " 'have': 30570,\n",
       " 'decided': 17219,\n",
       " 'withdraw': 74379,\n",
       " 'from': 26582,\n",
       " 'common': 13907,\n",
       " 'civility': 12845,\n",
       " 'in': 33505,\n",
       " 'order': 47900,\n",
       " 'define': 17460,\n",
       " 'own': 48610,\n",
       " 'world': 74699,\n",
       " 'coupled': 15414,\n",
       " 'destruction': 18214,\n",
       " 'is': 35099,\n",
       " 'not': 46714,\n",
       " 'perfect': 49947,\n",
       " 'movie': 44779,\n",
       " 'but': 10096,\n",
       " 'given': 28034,\n",
       " 'money': 44193,\n",
       " 'time': 67883,\n",
       " 'the': 67244,\n",
       " 'filmmaker': 24942,\n",
       " 'and': 3375,\n",
       " 'actors': 1741,\n",
       " 'had': 29807,\n",
       " 'remarkable': 55513,\n",
       " 'product': 52605,\n",
       " 'terms': 67035,\n",
       " 'explaining': 23541,\n",
       " 'motives': 44676,\n",
       " 'actions': 1723,\n",
       " 'murderers': 45110,\n",
       " 'better': 7288,\n",
       " 'than': 67198,\n",
       " 'elephant': 21607,\n",
       " 'film': 24904,\n",
       " 'that': 67222,\n",
       " 'gets': 27726,\n",
       " 'under': 70279,\n",
       " 'our': 48156,\n",
       " 'rationalistic': 54367,\n",
       " 'skin': 61440,\n",
       " 'far': 24147,\n",
       " 'almost': 2880,\n",
       " 'anything': 3859,\n",
       " 'are': 4269,\n",
       " 'likely': 39336,\n",
       " 'see': 59385,\n",
       " 'flawed': 25360,\n",
       " 'honest': 31970,\n",
       " 'with': 74378,\n",
       " 'terrible': 67049,\n",
       " 'honesty': 31972,\n",
       " 'words': 74651,\n",
       " 'can': 10580,\n",
       " 'describe': 18072,\n",
       " 'how': 32347,\n",
       " 'bad': 5669,\n",
       " 'this': 67505,\n",
       " 'explain': 23537,\n",
       " 'by': 10181,\n",
       " 'writing': 74886,\n",
       " 'only': 47657,\n",
       " 'too': 68298,\n",
       " 'yourself': 75410,\n",
       " 'get': 27716,\n",
       " 'at': 4910,\n",
       " 'grip': 29165,\n",
       " 'horrible': 32153,\n",
       " 'really': 54595,\n",
       " 'recommend': 54838,\n",
       " 'there': 67358,\n",
       " 'so': 62205,\n",
       " 'many': 41424,\n",
       " 'clichés': 13089,\n",
       " 'mistakes': 43840,\n",
       " 'all': 2767,\n",
       " 'other': 48119,\n",
       " 'negative': 45881,\n",
       " 'things': 67465,\n",
       " 'imagine': 33167,\n",
       " 'here': 31132,\n",
       " 'will': 74126,\n",
       " 'just': 36334,\n",
       " 'make': 41016,\n",
       " 'cry': 16123,\n",
       " 'start': 63760,\n",
       " 'technical': 66696,\n",
       " 'first': 25130,\n",
       " 'lot': 40076,\n",
       " 'regarding': 55184,\n",
       " 'airplane': 2471,\n",
       " 'won': 74533,\n",
       " 'list': 39560,\n",
       " 'them': 67292,\n",
       " 'mention': 42834,\n",
       " 'coloring': 13675,\n",
       " 'plane': 50966,\n",
       " 'didn': 18599,\n",
       " 'manage': 41189,\n",
       " 'show': 60687,\n",
       " 'an': 3284,\n",
       " 'airliner': 2464,\n",
       " 'colors': 13685,\n",
       " 'fictional': 24775,\n",
       " 'airline': 2463,\n",
       " 'instead': 34399,\n",
       " 'used': 71506,\n",
       " '747': 949,\n",
       " 'painted': 48788,\n",
       " 'original': 47979,\n",
       " 'boeing': 8320,\n",
       " 'livery': 39648,\n",
       " 'very': 72163,\n",
       " 'plot': 51165,\n",
       " 'stupid': 64708,\n",
       " 'has': 30449,\n",
       " 'been': 6723,\n",
       " 'done': 19895,\n",
       " 'times': 67903,\n",
       " 'before': 6762,\n",
       " 'much': 44890,\n",
       " 'ridiculous': 56540,\n",
       " 'moments': 44150,\n",
       " 'lost': 40073,\n",
       " 'count': 15363,\n",
       " 'early': 21050,\n",
       " 'also': 2933,\n",
       " 'was': 73209,\n",
       " 'on': 47611,\n",
       " 'guys': 29674,\n",
       " 'side': 60905,\n",
       " 'because': 6638,\n",
       " 'good': 28490,\n",
       " 'were': 73627,\n",
       " 'executive': 23363,\n",
       " 'decision': 17235,\n",
       " 'should': 60662,\n",
       " 'without': 74402,\n",
       " 'doubt': 20115,\n",
       " 'choice': 12413,\n",
       " 'over': 48333,\n",
       " 'one': 47628,\n",
       " 'turbulence': 69575,\n",
       " 'movies': 44805,\n",
       " 'fact': 23871,\n",
       " 'every': 23105,\n",
       " 'everyone': 23112,\n",
       " 'plays': 51074,\n",
       " 'part': 49250,\n",
       " 'pretty': 52340,\n",
       " 'well': 73581,\n",
       " 'little': 39620,\n",
       " 'nice': 46197,\n",
       " 'belushi': 6982,\n",
       " 'chance': 11756,\n",
       " 'live': 39633,\n",
       " 'his': 31569,\n",
       " 'life': 39251,\n",
       " 'differently': 18640,\n",
       " 'ends': 22147,\n",
       " 'up': 71330,\n",
       " 'realizing': 54590,\n",
       " 'he': 30665,\n",
       " 'going': 28383,\n",
       " 'as': 4616,\n",
       " 'or': 47846,\n",
       " 'maybe': 42121,\n",
       " 'shows': 60715,\n",
       " 'us': 71492,\n",
       " 'we': 73388,\n",
       " 'ought': 48149,\n",
       " 'take': 66222,\n",
       " 'advantage': 2016,\n",
       " 'opportunities': 47793,\n",
       " 'ones': 47636,\n",
       " 'cannot': 10666,\n",
       " 'if': 33013,\n",
       " 'video': 72287,\n",
       " 'around': 4446,\n",
       " '10': 40,\n",
       " 'investment': 34899,\n",
       " 'highly': 31393,\n",
       " 'talented': 66257,\n",
       " 'filmmakers': 24943,\n",
       " 'germany': 27674,\n",
       " 'now': 46821,\n",
       " 'none': 46565,\n",
       " 'associated': 4815,\n",
       " 'producers': 52602,\n",
       " 'actually': 1754,\n",
       " 'invest': 34885,\n",
       " 'something': 62466,\n",
       " 'like': 39327,\n",
       " 'could': 15333,\n",
       " 'made': 40762,\n",
       " 'films': 24956,\n",
       " 'budget': 9709,\n",
       " 'garbage': 27200,\n",
       " 'entertaining': 22391,\n",
       " 'seven': 59866,\n",
       " 'grown': 29306,\n",
       " 'running': 57586,\n",
       " 'dwarfs': 20926,\n",
       " 'pretending': 52322,\n",
       " 'funny': 26793,\n",
       " 'though': 67571,\n",
       " 'producer': 52599,\n",
       " 'happens': 30225,\n",
       " 'oldest': 47529,\n",
       " 'guy': 29670,\n",
       " 'bunch': 9875,\n",
       " 'playing': 51064,\n",
       " 'youngest': 75398,\n",
       " 'dwarf': 20923,\n",
       " 'filled': 24891,\n",
       " 'scream': 59044,\n",
       " 'captions': 10796,\n",
       " 'saying': 58503,\n",
       " 'supposed': 65434,\n",
       " 'laugh': 38479,\n",
       " 'hard': 30269,\n",
       " 'believe': 6910,\n",
       " 'crap': 15617,\n",
       " 'comedy': 13768,\n",
       " 'people': 49873,\n",
       " 'stood': 64233,\n",
       " 'left': 38778,\n",
       " 'cinema': 12710,\n",
       " '30': 664,\n",
       " 'minutes': 43588,\n",
       " 'into': 34767,\n",
       " 'same': 58060,\n",
       " 'wasting': 73258,\n",
       " 'my': 45289,\n",
       " 'pain': 48770,\n",
       " 've': 71924,\n",
       " 'evidence': 23133,\n",
       " 'confirmed': 14367,\n",
       " 'suspicions': 65615,\n",
       " 'kids': 37084,\n",
       " '14': 172,\n",
       " '22': 571,\n",
       " 'put': 53461,\n",
       " 'dvd': 20906,\n",
       " 'titanic': 68027,\n",
       " 'fantastic': 24128,\n",
       " 'state': 63785,\n",
       " 'art': 4524,\n",
       " 'mega': 42591,\n",
       " 'screen': 59059,\n",
       " 'home': 31882,\n",
       " 'entertainment': 22393,\n",
       " 'type': 69787,\n",
       " 'deal': 17063,\n",
       " 'seen': 59414,\n",
       " 'moment': 44145,\n",
       " 'kate': 36673,\n",
       " 'leo': 38954,\n",
       " 'celine': 11510,\n",
       " 'dion': 18833,\n",
       " 'most': 44626,\n",
       " 'felt': 24566,\n",
       " 'whole': 73944,\n",
       " 'shortly': 60644,\n",
       " 'after': 2211,\n",
       " 'epic': 22534,\n",
       " 'started': 63761,\n",
       " 'restless': 56076,\n",
       " 'some': 62444,\n",
       " 'asking': 4701,\n",
       " 'others': 48123,\n",
       " 'call': 10427,\n",
       " 'when': 73781,\n",
       " 'iceberg': 32887,\n",
       " 'appears': 4004,\n",
       " 'hour': 32302,\n",
       " 'half': 29943,\n",
       " 'girls': 27993,\n",
       " 'still': 64090,\n",
       " 'shouting': 60674,\n",
       " 'stampede': 63637,\n",
       " 'followed': 25741,\n",
       " 'came': 10493,\n",
       " 'back': 5602,\n",
       " 'sinking': 61222,\n",
       " 'sat': 58334,\n",
       " 'open': 47733,\n",
       " 'mouthed': 44757,\n",
       " 'emitting': 21913,\n",
       " 'ohs': 47460,\n",
       " 'outs': 48272,\n",
       " 'thought': 67573,\n",
       " 'burst': 10013,\n",
       " 'scene': 58658,\n",
       " 'hours': 32305,\n",
       " 'waiting': 72962,\n",
       " 'bloody': 8089,\n",
       " 'thing': 67457,\n",
       " 'sink': 61218,\n",
       " 'about': 1354,\n",
       " 'rest': 56060,\n",
       " 'dr': 20236,\n",
       " 'zivagho': 75763,\n",
       " 'instance': 34391,\n",
       " 'similar': 61097,\n",
       " 'takes': 66237,\n",
       " 'place': 50922,\n",
       " 'within': 74397,\n",
       " 'period': 49991,\n",
       " 'teaches': 66642,\n",
       " 'spit': 63119,\n",
       " 'look': 39951,\n",
       " 'faces': 23849,\n",
       " 'hands': 30141,\n",
       " 'supposedly': 65435,\n",
       " 'creme': 15777,\n",
       " 'de': 17031,\n",
       " 'la': 37924,\n",
       " 'class': 12937,\n",
       " 'dining': 18805,\n",
       " 'room': 57156,\n",
       " 'ship': 60454,\n",
       " 'historical': 31593,\n",
       " 'details': 18232,\n",
       " 'find': 25008,\n",
       " 'storyline': 64301,\n",
       " 'thin': 67455,\n",
       " 'introduce': 34805,\n",
       " 'guns': 29601,\n",
       " 'shootings': 60593,\n",
       " 'real': 54564,\n",
       " 'standards': 63652,\n",
       " 'efforts': 21368,\n",
       " 'focus': 25676,\n",
       " 'special': 62888,\n",
       " 'effects': 21343,\n",
       " 'opening': 47737,\n",
       " 'week': 73475,\n",
       " 'went': 73621,\n",
       " 'become': 6661,\n",
       " 'highest': 31380,\n",
       " 'grossing': 29250,\n",
       " 'know': 37474,\n",
       " 'sub': 64778,\n",
       " 'par': 49042,\n",
       " 'television': 66833,\n",
       " 'pilot': 50707,\n",
       " 'delivers': 17651,\n",
       " 'great': 28977,\n",
       " 'springboard': 63330,\n",
       " 'sci': 58899,\n",
       " 'fi': 24747,\n",
       " 'fans': 24109,\n",
       " 'ideal': 32930,\n",
       " 'program': 52670,\n",
       " 'deliver': 17642,\n",
       " 'series': 59774,\n",
       " 'spectacular': 62932,\n",
       " 'having': 30585,\n",
       " 'intelligent': 34506,\n",
       " 'interesting': 34589,\n",
       " 'script': 59106,\n",
       " 'doesn': 19733,\n",
       " 'hurt': 32679,\n",
       " 'either': 21485,\n",
       " 'stargate': 63720,\n",
       " 'sg1': 59953,\n",
       " 'currently': 16339,\n",
       " 'favorite': 24367,\n",
       " 'programs': 52681,\n",
       " 'way': 73362,\n",
       " 'telling': 66846,\n",
       " 'story': 64290,\n",
       " 'found': 26114,\n",
       " 'rather': 54354,\n",
       " 'odd': 47305,\n",
       " 'jumped': 36272,\n",
       " 'through': 67654,\n",
       " 'no': 46465,\n",
       " 'idea': 32929,\n",
       " 'whats': 73743,\n",
       " 'happening': 30223,\n",
       " 'anyway': 3861,\n",
       " 'line': 39445,\n",
       " 'although': 2974,\n",
       " 'simple': 61127,\n",
       " 'touching': 68518,\n",
       " 'met': 43010,\n",
       " 'someone': 62451,\n",
       " 'fell': 24545,\n",
       " 'love': 40154,\n",
       " 'completely': 14047,\n",
       " 'broke': 9446,\n",
       " 'last': 38401,\n",
       " 'promoted': 52753,\n",
       " 'deadly': 17051,\n",
       " 'agony': 2325,\n",
       " 'hasn': 30464,\n",
       " 'go': 28280,\n",
       " 'never': 46084,\n",
       " 'forget': 25949,\n",
       " 'kind': 37166,\n",
       " 'say': 58496,\n",
       " 'am': 3020,\n",
       " 'touched': 68516,\n",
       " 'actor': 1739,\n",
       " 'shown': 60712,\n",
       " 'performance': 49967,\n",
       " 'showing': 60708,\n",
       " 'between': 7306,\n",
       " 'characters': 11872,\n",
       " 'wish': 74340,\n",
       " 'happy': 30238,\n",
       " 'ending': 22124,\n",
       " 'single': 61199,\n",
       " 'worst': 74748,\n",
       " 'ever': 23079,\n",
       " 'theater': 67251,\n",
       " 'saw': 58474,\n",
       " 'austin': 5200,\n",
       " 'festival': 24687,\n",
       " '2004': 500,\n",
       " 'blew': 7963,\n",
       " 'mind': 43460,\n",
       " 'accepted': 1493,\n",
       " 'premise': 52176,\n",
       " 'seemed': 59408,\n",
       " 'somewhere': 62475,\n",
       " 'apart': 3890,\n",
       " 'tried': 69132,\n",
       " 'musical': 45179,\n",
       " 'talent': 66256,\n",
       " 'music': 45178,\n",
       " 'consisted': 14596,\n",
       " 'cheesy': 12116,\n",
       " 'piano': 50543,\n",
       " 'sounded': 62664,\n",
       " 'stereo': 63989,\n",
       " 'filming': 24939,\n",
       " 'lyrics': 40557,\n",
       " 'terribly': 67052,\n",
       " 'written': 74889,\n",
       " 'weren': 73631,\n",
       " 'obvious': 47220,\n",
       " 'rhymes': 56441,\n",
       " 'groan': 29202,\n",
       " 'inducing': 33888,\n",
       " 'showed': 60697,\n",
       " 'stretching': 64483,\n",
       " 'try': 69397,\n",
       " 'work': 74660,\n",
       " 'sing': 61186,\n",
       " 'making': 41037,\n",
       " 'right': 56595,\n",
       " 'case': 11121,\n",
       " 'luckily': 40292,\n",
       " 'talking': 66281,\n",
       " 'singing': 61198,\n",
       " 'rhyme': 56438,\n",
       " 'me': 42402,\n",
       " 'cringe': 15841,\n",
       " 'especially': 22820,\n",
       " 'attempted': 5033,\n",
       " 'harmony': 30369,\n",
       " 'addresses': 1826,\n",
       " 'acting': 1704,\n",
       " 'dialog': 18497,\n",
       " 'scenes': 58665,\n",
       " 'obviously': 47221,\n",
       " 'enough': 22299,\n",
       " 'coverage': 15471,\n",
       " 'editor': 21259,\n",
       " 'consistently': 14600,\n",
       " 'choices': 12414,\n",
       " 'while': 73814,\n",
       " 'cutting': 16434,\n",
       " 'least': 38697,\n",
       " 'director': 18876,\n",
       " 'willing': 74151,\n",
       " 'admit': 1918,\n",
       " 'wanted': 73103,\n",
       " 'until': 71235,\n",
       " 'added': 1803,\n",
       " 'hook': 32034,\n",
       " 'hope': 32079,\n",
       " 'investors': 34903,\n",
       " 'sure': 65472,\n",
       " 'write': 74875,\n",
       " 'mistake': 43837,\n",
       " 'again': 2238,\n",
       " 'convoluted': 14944,\n",
       " 'spoiler': 63188,\n",
       " 'warning': 73174,\n",
       " 'unsure': 71196,\n",
       " 'giving': 28041,\n",
       " 'away': 5416,\n",
       " 'audience': 5117,\n",
       " 'sees': 59423,\n",
       " 'man': 41187,\n",
       " 'jack': 35339,\n",
       " 'ripper': 56701,\n",
       " 'garb': 27199,\n",
       " 'murder': 45106,\n",
       " 'old': 47524,\n",
       " 'alley': 2800,\n",
       " 'hundred': 32610,\n",
       " 'years': 75214,\n",
       " 'ago': 2313,\n",
       " 'then': 67310,\n",
       " 'modern': 44010,\n",
       " 'australian': 5207,\n",
       " 'couple': 15413,\n",
       " 'looking': 39959,\n",
       " 'house': 32307,\n",
       " 'unbelievably': 70106,\n",
       " 'long': 39906,\n",
       " 'tour': 68540,\n",
       " 'husband': 32687,\n",
       " 'figure': 24861,\n",
       " 'mirror': 43622,\n",
       " '105': 66,\n",
       " 'year': 75203,\n",
       " 'woman': 74513,\n",
       " 'lived': 39634,\n",
       " 'large': 38324,\n",
       " 'iron': 35020,\n",
       " 'panels': 48942,\n",
       " 'covering': 15474,\n",
       " 'wall': 73016,\n",
       " 'den': 17803,\n",
       " 'fashioned': 24261,\n",
       " 'straight': 64340,\n",
       " 'razor': 54482,\n",
       " 'falls': 24008,\n",
       " 'out': 48165,\n",
       " 'renovating': 55652,\n",
       " 'keeps': 36812,\n",
       " 'guess': 29433,\n",
       " 'becomes': 6664,\n",
       " 'possessed': 51743,\n",
       " 'starts': 63771,\n",
       " 'weird': 73545,\n",
       " 'dreams': 20375,\n",
       " 'oh': 47445,\n",
       " 'yeah': 75202,\n",
       " 'unable': 70004,\n",
       " 'baby': 5566,\n",
       " 'firing': 25120,\n",
       " 'blanks': 7870,\n",
       " 'mold': 44096,\n",
       " 'seems': 59412,\n",
       " 'climbing': 13122,\n",
       " 'removes': 55589,\n",
       " 'shape': 60124,\n",
       " 'person': 50111,\n",
       " 'late': 38416,\n",
       " 'cache': 10268,\n",
       " 'murders': 45115,\n",
       " 'body': 8304,\n",
       " 'guard': 29395,\n",
       " 'co': 13318,\n",
       " 'worker': 74669,\n",
       " 'steals': 63866,\n",
       " 'wife': 74062,\n",
       " 'suddenly': 65024,\n",
       " 'pregnant': 52144,\n",
       " 'hell': 30965,\n",
       " 'knows': 37486,\n",
       " 'nothing': 46741,\n",
       " 'explained': 23540,\n",
       " 'child': 12290,\n",
       " 'serial': 59769,\n",
       " 'killer': 37121,\n",
       " 'sister': 61288,\n",
       " 'keep': 36806,\n",
       " 'contained': 14715,\n",
       " 'cellar': 11514,\n",
       " 'locked': 39765,\n",
       " 'down': 20165,\n",
       " 'family': 24051,\n",
       " 'starved': 63775,\n",
       " 'death': 17095,\n",
       " 'concealed': 14177,\n",
       " 'mr': 44854,\n",
       " 'hobbs': 31702,\n",
       " 'desperate': 18157,\n",
       " 'killing': 37127,\n",
       " 'murdered': 45108,\n",
       " 'pattern': 49494,\n",
       " 'motive': 44673,\n",
       " 'does': 19730,\n",
       " 'demon': 17752,\n",
       " 'spawn': 62858,\n",
       " 'managed': 41191,\n",
       " 'infiltrate': 34021,\n",
       " 'semen': 59547,\n",
       " 'able': 1308,\n",
       " 'subdue': 64795,\n",
       " 'huge': 32466,\n",
       " 'burly': 9975,\n",
       " 'security': 59352,\n",
       " 'overpower': 48483,\n",
       " 'powerful': 51894,\n",
       " 'voltage': 72720,\n",
       " 'system': 66053,\n",
       " 'australia': 5206,\n",
       " 'knock': 37454,\n",
       " 'him': 31474,\n",
       " 'across': 1694,\n",
       " 'simply': 61143,\n",
       " 'light': 39292,\n",
       " 'wire': 74308,\n",
       " 'stay': 63833,\n",
       " 'she': 60235,\n",
       " 'reincarnated': 55313,\n",
       " 'such': 64995,\n",
       " 'frustrating': 26635,\n",
       " 'experience': 23510,\n",
       " 'pbs': 49594,\n",
       " 'station': 63803,\n",
       " 'ask': 4696,\n",
       " 'enjoyable': 22256,\n",
       " 'aspect': 4711,\n",
       " 'seeing': 59397,\n",
       " 'boxer': 8901,\n",
       " 'shorts': 60646,\n",
       " 'couldn': 15335,\n",
       " 'redeem': 54954,\n",
       " 'muddled': 44910,\n",
       " 'incoherent': 33650,\n",
       " 'mess': 42981,\n",
       " 'izzard': 35315,\n",
       " 'damn': 16681,\n",
       " 'boggles': 8354,\n",
       " 'more': 44463,\n",
       " 'known': 37484,\n",
       " 'command': 13806,\n",
       " 'crowd': 16021,\n",
       " 'timing': 67923,\n",
       " 'monologue': 44251,\n",
       " 'star': 63699,\n",
       " 'wars': 73197,\n",
       " 'kill': 37115,\n",
       " 'ya': 75060,\n",
       " 'stand': 63645,\n",
       " 'performers': 49972,\n",
       " 'wit': 74359,\n",
       " 'probably': 52519,\n",
       " 'dolph': 19820,\n",
       " 'want': 73100,\n",
       " 'expect': 23476,\n",
       " 'don': 19873,\n",
       " 'waste': 73247,\n",
       " 'your': 75407,\n",
       " 'miserable': 43695,\n",
       " 'cop': 15015,\n",
       " 'interests': 34591,\n",
       " 'brother': 9513,\n",
       " 'killed': 37120,\n",
       " 'tries': 69135,\n",
       " 'character': 11850,\n",
       " 'plain': 50951,\n",
       " 'stumbles': 64671,\n",
       " 'aimlessly': 2426,\n",
       " 'pointless': 51326,\n",
       " 'germans': 27673,\n",
       " 'mowed': 44827,\n",
       " 'machine': 40670,\n",
       " 'gun': 29555,\n",
       " 'die': 18601,\n",
       " 'unless': 70831,\n",
       " 'its': 35254,\n",
       " 'dramatic': 20288,\n",
       " 'purposes': 53414,\n",
       " 'holes': 31795,\n",
       " 'laughable': 38480,\n",
       " 'where': 73787,\n",
       " 'german': 27668,\n",
       " 'soldiers': 62370,\n",
       " 'once': 47616,\n",
       " 'rolled': 57051,\n",
       " 'fuel': 26676,\n",
       " 'tank': 66384,\n",
       " 'towards': 68567,\n",
       " 'train': 68696,\n",
       " 'erik': 22675,\n",
       " 'estrada': 22910,\n",
       " 'please': 51102,\n",
       " 'hijacking': 31419,\n",
       " 'moronic': 44532,\n",
       " 'leave': 38711,\n",
       " 'track': 68634,\n",
       " 'drive': 20466,\n",
       " 'bonk': 8530,\n",
       " 'myself': 45321,\n",
       " 'head': 30667,\n",
       " 'ball': 5869,\n",
       " 'peen': 49721,\n",
       " 'hammer': 30053,\n",
       " 'sit': 61297,\n",
       " 'mean': 42417,\n",
       " 'seriously': 59778,\n",
       " '60s': 893,\n",
       " 'produced': 52598,\n",
       " '88': 1004,\n",
       " '1988': 446,\n",
       " 'team': 66654,\n",
       " 'believable': 6908,\n",
       " 'horrid': 32156,\n",
       " 'excuse': 23343,\n",
       " 'watch': 73265,\n",
       " 'need': 45854,\n",
       " 'tele': 66776,\n",
       " 'sevalas': 59865,\n",
       " 'green': 28999,\n",
       " 'beret': 7112,\n",
       " 'john': 35987,\n",
       " 'wayne': 73371,\n",
       " 'considering': 14584,\n",
       " 'picking': 50570,\n",
       " 'new': 46095,\n",
       " 'jet': 35783,\n",
       " 'li': 39142,\n",
       " 'kicking': 37055,\n",
       " 'brainless': 8988,\n",
       " 'hand': 30095,\n",
       " 'fighting': 24851,\n",
       " 'grabbed': 28733,\n",
       " 'title': 68045,\n",
       " 'unfortunatly': 70619,\n",
       " 'contains': 14720,\n",
       " 'battles': 6437,\n",
       " 'ala': 2554,\n",
       " 'chow': 12500,\n",
       " 'yun': 75476,\n",
       " 'fat': 24288,\n",
       " 'nowhere': 46826,\n",
       " 'near': 45785,\n",
       " 'company': 13958,\n",
       " 'acrobatic': 1689,\n",
       " 'thus': 67749,\n",
       " 'let': 39033,\n",
       " 'faucet': 24339,\n",
       " 'totaly': 68490,\n",
       " 'unexpected': 70539,\n",
       " 'jackie': 35353,\n",
       " 'chan': 11755,\n",
       " 'alas': 2579,\n",
       " 'fist': 25159,\n",
       " 'legend': 38798,\n",
       " 'tai': 66183,\n",
       " 'chi': 12232,\n",
       " 'master': 41879,\n",
       " 'enforcer': 22183,\n",
       " 'dissapointment': 19381,\n",
       " 'rating': 54357,\n",
       " 'martial': 41723,\n",
       " 'arts': 4590,\n",
       " 'overall': 48344,\n",
       " 'score': 58955,\n",
       " 'barbra': 6121,\n",
       " 'streisand': 64458,\n",
       " 'debut': 17158,\n",
       " 'pinnacle': 50767,\n",
       " 'history': 31599,\n",
       " 'any': 3843,\n",
       " 'media': 42517,\n",
       " 'cleverly': 13073,\n",
       " 'divided': 19557,\n",
       " 'three': 67610,\n",
       " 'separate': 59681,\n",
       " 'acts': 1747,\n",
       " 'minimize': 43526,\n",
       " 'interruption': 34698,\n",
       " 'commercial': 13859,\n",
       " 'breaks': 9138,\n",
       " 'bold': 8398,\n",
       " 'yet': 75272,\n",
       " 'masterful': 41884,\n",
       " 'drop': 20499,\n",
       " 'typical': 69800,\n",
       " 'variety': 71858,\n",
       " 'format': 25995,\n",
       " 'which': 73803,\n",
       " 'guest': 29438,\n",
       " 'stars': 63749,\n",
       " 'nor': 46627,\n",
       " 'forced': 25856,\n",
       " 'banter': 6054,\n",
       " 'carry': 11052,\n",
       " 'entire': 22416,\n",
       " 'her': 31107,\n",
       " 'shoulders': 60667,\n",
       " 'alone': 2891,\n",
       " 'risky': 56733,\n",
       " 'move': 44766,\n",
       " 'paid': 48767,\n",
       " 'off': 47358,\n",
       " 'enormously': 22297,\n",
       " 'name': 45499,\n",
       " 'set': 59829,\n",
       " 'standard': 63648,\n",
       " 'programming': 52680,\n",
       " 'filmed': 24922,\n",
       " 'glorious': 28215,\n",
       " 'black': 7741,\n",
       " 'white': 73883,\n",
       " 'adds': 1828,\n",
       " 'effectiveness': 21342,\n",
       " 'flawlessly': 25363,\n",
       " 'conceived': 14190,\n",
       " 'impressively': 33450,\n",
       " 'shot': 60652,\n",
       " 'however': 32358,\n",
       " 'makes': 41026,\n",
       " 'truly': 69364,\n",
       " 'transcendent': 68763,\n",
       " 'herself': 31221,\n",
       " 'watching': 73278,\n",
       " '23': 586,\n",
       " 'performer': 49971,\n",
       " 'navigate': 45738,\n",
       " '55': 851,\n",
       " 'minute': 43584,\n",
       " 'runtime': 57590,\n",
       " 'less': 39018,\n",
       " 'thrilling': 67631,\n",
       " 'voice': 72679,\n",
       " 'performs': 49974,\n",
       " 'third': 67488,\n",
       " 'gives': 28038,\n",
       " 'immense': 33232,\n",
       " 'power': 51889,\n",
       " 'soon': 62536,\n",
       " 'follow': 25739,\n",
       " 'big': 7457,\n",
       " 'biggest': 7469,\n",
       " 'asset': 4785,\n",
       " 'boldness': 8403,\n",
       " 'allowing': 2835,\n",
       " 'stage': 63544,\n",
       " 'songs': 62511,\n",
       " 'brief': 9276,\n",
       " 'snippet': 62113,\n",
       " 'leonard': 38958,\n",
       " 'bernstein': 7178,\n",
       " 'barbara': 6092,\n",
       " 'proceeds': 52553,\n",
       " 'wander': 73074,\n",
       " 'multi': 44996,\n",
       " 'level': 39075,\n",
       " 'studio': 64649,\n",
       " 'performing': 49973,\n",
       " 'frantic': 26283,\n",
       " 'version': 72141,\n",
       " 'disney': 19241,\n",
       " 'classic': 12940,\n",
       " 'verses': 72139,\n",
       " 'stops': 64257,\n",
       " 'various': 71859,\n",
       " 'levels': 39083,\n",
       " 'terrific': 67055,\n",
       " 'numbers': 46917,\n",
       " 'haunting': 30555,\n",
       " 'thundering': 67731,\n",
       " 'wine': 74235,\n",
       " 'taste': 66525,\n",
       " 'halfway': 29952,\n",
       " 'act': 1696,\n",
       " 'enters': 22383,\n",
       " 'childhood': 12295,\n",
       " 'strains': 64355,\n",
       " 'kid': 37059,\n",
       " 'energetic': 22161,\n",
       " 'performances': 49968,\n",
       " 'five': 25187,\n",
       " 'sweet': 65772,\n",
       " 'zoo': 75813,\n",
       " 'romping': 57118,\n",
       " 'among': 3209,\n",
       " 'sized': 61339,\n",
       " 'illusion': 33124,\n",
       " 'eventually': 23075,\n",
       " 'shattered': 60205,\n",
       " 'finds': 25014,\n",
       " 'fantasy': 24135,\n",
       " 'sings': 61207,\n",
       " 'innocence': 34234,\n",
       " 'lovely': 40177,\n",
       " 'wonder': 74534,\n",
       " 'dashes': 16901,\n",
       " 'onto': 47679,\n",
       " 'platform': 51021,\n",
       " 'surrounded': 65554,\n",
       " 'full': 26714,\n",
       " 'musicians': 45185,\n",
       " 'rousing': 57355,\n",
       " 'rendition': 55621,\n",
       " 'thunderous': 67734,\n",
       " 'applause': 4033,\n",
       " 'ii': 33063,\n",
       " 'begins': 6800,\n",
       " 'hamming': 30067,\n",
       " 'campy': 10572,\n",
       " 'got': 28645,\n",
       " 'blues': 8164,\n",
       " 'delivering': 17649,\n",
       " 'pearl': 49637,\n",
       " 'istanbul': 35204,\n",
       " 'heads': 30704,\n",
       " 'bergdorf': 7121,\n",
       " 'goodman': 28514,\n",
       " 'department': 17906,\n",
       " 'store': 64261,\n",
       " 'allows': 2836,\n",
       " 'medley': 42560,\n",
       " 'poverty': 51880,\n",
       " 'parading': 49059,\n",
       " 'elegant': 21591,\n",
       " 'fashions': 24264,\n",
       " 'segment': 59437,\n",
       " 'brightest': 9307,\n",
       " 'highlight': 31389,\n",
       " 'critics': 15908,\n",
       " 'high': 31372,\n",
       " 'points': 51330,\n",
       " 'include': 33636,\n",
       " 'restrained': 56083,\n",
       " 'second': 59309,\n",
       " 'rose': 57215,\n",
       " 'appearing': 4003,\n",
       " 'latin': 38439,\n",
       " 'bullfighter': 9818,\n",
       " 'tune': 69533,\n",
       " 'nobody': 46481,\n",
       " 'portraying': 51695,\n",
       " 'frustrated': 26633,\n",
       " 'paperboy': 49019,\n",
       " 'mugging': 44938,\n",
       " 'spare': 62810,\n",
       " 'dime': 18750,\n",
       " 'concert': 14214,\n",
       " 'pieces': 50619,\n",
       " 'concepts': 14204,\n",
       " 'thrives': 67637,\n",
       " 'belting': 6974,\n",
       " 'gravity': 28953,\n",
       " 'defying': 17513,\n",
       " 'sun': 65215,\n",
       " 'comes': 13779,\n",
       " 'continues': 14792,\n",
       " 'amaze': 3063,\n",
       " 'viewer': 72341,\n",
       " 'yearling': 75206,\n",
       " 'ballad': 5870,\n",
       " 'choose': 12447,\n",
       " 'scorching': 58954,\n",
       " 'lover': 40179,\n",
       " 'come': 13755,\n",
       " 'impassioned': 33306,\n",
       " 'form': 25983,\n",
       " ...}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 75669\n",
      "day 16986\n",
      "leads 38653\n",
      "you 75381\n",
      "to 68091\n",
      "think 67468\n",
      "even 23059\n",
      "re 54503\n",
      "why 73998\n",
      "two 69757\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for v in vect.vocabulary_:\n",
    "    print(v, vect.vocabulary_[v])\n",
    "    i+=1\n",
    "    if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "75911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000000000001', '00001', '00015']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['doppelgangers', 'doppelgänger', 'dopplebangers', 'doppleganger', 'doppler']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'burress',\n",
       " 'dop',\n",
       " 'hallucinogenics',\n",
       " 'looping',\n",
       " 'periphery',\n",
       " 'shaffer',\n",
       " 'una']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ís', 'ísnt', 'østbye', 'über', 'üvegtigris']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "display(type(feature_names), len(feature_names))\n",
    "display(feature_names[:5], feature_names[20010:20015], feature_names[::10000], feature_names[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaliyah'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  91 (1, 75911)\n",
      " 120 (1, 75911)\n",
      "  62 (1, 75911)\n",
      "  95 (1, 75911)\n",
      " 166 (1, 75911)\n",
      "  47 (1, 75911)\n",
      "  78 (1, 75911)\n",
      " 151 (1, 75911)\n",
      " 220 (1, 75911)\n",
      "  43 (1, 75911)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # a = X_train[i].toarray()\n",
    "    a = X_train[i]\n",
    "    print('%4d %s' % ((a > 0).sum(), a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "         4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 2, 2, 1, 2, 1, 3, 2, 1, 2, 1, 4, 3, 1, 2, 3, 1, 1,\n",
       "         1, 1, 1, 1, 2, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0 = X_train[0]\n",
    "doc_0[doc_0>0]\n",
    "\n",
    "#X_train[0][X_train[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 75911)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723 actions 1\n",
      "1741 actors 1\n",
      "2880 almost 1\n",
      "3375 and 2\n",
      "3859 anything 1\n",
      "4269 are 1\n",
      "6512 be 1\n",
      "6852 being 2\n",
      "7288 better 2\n",
      "7341 beyond 1\n",
      "7716 bizarre 1\n",
      "8922 boys 1\n",
      "10096 but 2\n",
      "10809 captures 1\n",
      "12845 civility 1\n",
      "12958 classmates 1\n",
      "13888 commit 1\n",
      "13907 common 1\n",
      "15414 coupled 1\n",
      "16986 day 1\n",
      "17219 decided 1\n",
      "17460 define 1\n",
      "18214 destruction 1\n",
      "18588 did 1\n",
      "19634 do 1\n",
      "21607 elephant 1\n",
      "23059 even 1\n",
      "23541 explaining 1\n",
      "24147 far 2\n",
      "24904 film 2\n",
      "24942 filmmaker 1\n",
      "25360 flawed 1\n",
      "25839 for 1\n",
      "26582 from 1\n",
      "27726 gets 1\n",
      "28034 given 1\n",
      "29807 had 1\n",
      "30570 have 1\n",
      "31970 honest 1\n",
      "31972 honesty 1\n",
      "32540 humans 1\n",
      "33505 in 3\n",
      "35099 is 4\n",
      "35211 it 5\n",
      "38653 leads 1\n",
      "39336 likely 1\n",
      "42764 men 1\n",
      "43993 mode 1\n",
      "44193 money 1\n",
      "44676 motives 1\n",
      "44779 movie 1\n",
      "45110 murderers 1\n",
      "45209 must 1\n",
      "45268 mutual 2\n",
      "46714 not 1\n",
      "47352 of 4\n",
      "47900 order 1\n",
      "48156 our 1\n",
      "48610 own 1\n",
      "49947 perfect 1\n",
      "52605 product 1\n",
      "54367 rationalistic 1\n",
      "54503 re 1\n",
      "55513 remarkable 1\n",
      "59385 see 1\n",
      "61440 skin 1\n",
      "61588 slaughtering 1\n",
      "65104 suicide 2\n",
      "67035 terms 2\n",
      "67049 terrible 1\n",
      "67198 than 2\n",
      "67222 that 1\n",
      "67244 the 3\n",
      "67280 their 2\n",
      "67409 they 1\n",
      "67468 think 2\n",
      "67883 time 1\n",
      "68091 to 4\n",
      "69757 two 3\n",
      "70279 under 1\n",
      "72211 via 2\n",
      "73731 what 3\n",
      "73935 who 1\n",
      "73998 why 1\n",
      "74378 with 1\n",
      "74379 withdraw 1\n",
      "74699 world 1\n",
      "74762 would 1\n",
      "75381 you 2\n",
      "75392 young 2\n",
      "75669 zero 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(75911):\n",
    "    n = doc_0[0,i]\n",
    "    if n>0: print(i,feature_names[i],n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 모델 적용\n",
    "- LogisticRegression 과 교차검증 적용 (학습데이터만 사용함)\n",
    "- LogisticRegression 의 설정값인 C 를 바꿔가면서 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87724982, 0.87365011, 0.87650024])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(C=1), X_train, y_train) # default cv=3\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87568"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "model.fit(train_data, train_target)\n",
    "model.score(test_data, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트세트를 적용하여 점수 확인\n",
    "- C 값으로 0.1 을 적용한다\n",
    "> **주의** : text_train 으로 단어집을 만들었으므로 text_test 에는 단어집에 없는 단어가 있을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 75911)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87884"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97504"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84809215, 0.84473242, 0.85441671])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(BernoulliNB(), X_train, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82604"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM 을 적용하면 시간이 아주 오래 걸린다. 결과만 참고하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71358291, 0.70230382, 0.71915506])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.svm import SVC\n",
    "\n",
    "scores = cross_val_score(SVC(), X_train, y_train)\n",
    "scores'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 속성(단어) 줄이기\n",
    "- CountVectorizer 의 min_df=5 로 설정 (5개 이하로 문서에 나타나는 단어는 제외)\n",
    "- 특성의 갯수가 줄어서 처리 속도가 빨라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_5 = CountVectorizer(min_df=5)\n",
    "vect_5.fit(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75911, 27264)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_), len(vect_5.vocabulary_) # 75911 => 27264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_5 = vect_5.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87520998, 0.87149028, 0.87554009])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train_5, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84701224, 0.84521238, 0.85345655])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(BernoulliNB(), X_train_5, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 적용\n",
    "- CountVectorizer(stop_words='english', max_df=...)\n",
    "- stop_words : 불용어 목록을 지정함\n",
    "- max_df : 너무 자주 나타나는 단어를 제외함 (0~1 사이의 비율 지정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CountVectorizer in module sklearn.feature_extraction.text:\n",
      "\n",
      "class CountVectorizer(sklearn.base.BaseEstimator, VectorizerMixin)\n",
      " |  CountVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n",
      " |  \n",
      " |  Convert a collection of text documents to a matrix of token counts\n",
      " |  \n",
      " |  This implementation produces a sparse representation of the counts using\n",
      " |  scipy.sparse.csr_matrix.\n",
      " |  \n",
      " |  If you do not provide an a-priori dictionary and you do not use an analyzer\n",
      " |  that does some kind of feature selection then the number of features will\n",
      " |  be equal to the vocabulary size found by analyzing the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  input : string {'filename', 'file', 'content'}\n",
      " |      If 'filename', the sequence passed as an argument to fit is\n",
      " |      expected to be a list of filenames that need reading to fetch\n",
      " |      the raw content to analyze.\n",
      " |  \n",
      " |      If 'file', the sequence items must have a 'read' method (file-like\n",
      " |      object) that is called to fetch the bytes in memory.\n",
      " |  \n",
      " |      Otherwise the input is expected to be the sequence strings or\n",
      " |      bytes items are expected to be analyzed directly.\n",
      " |  \n",
      " |  encoding : string, 'utf-8' by default.\n",
      " |      If bytes or files are given to analyze, this encoding is used to\n",
      " |      decode.\n",
      " |  \n",
      " |  decode_error : {'strict', 'ignore', 'replace'}\n",
      " |      Instruction on what to do if a byte sequence is given to analyze that\n",
      " |      contains characters not of the given `encoding`. By default, it is\n",
      " |      'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      " |      values are 'ignore' and 'replace'.\n",
      " |  \n",
      " |  strip_accents : {'ascii', 'unicode', None}\n",
      " |      Remove accents during the preprocessing step.\n",
      " |      'ascii' is a fast method that only works on characters that have\n",
      " |      an direct ASCII mapping.\n",
      " |      'unicode' is a slightly slower method that works on any characters.\n",
      " |      None (default) does nothing.\n",
      " |  \n",
      " |  analyzer : string, {'word', 'char', 'char_wb'} or callable\n",
      " |      Whether the feature should be made of word or character n-grams.\n",
      " |      Option 'char_wb' creates character n-grams only from text inside\n",
      " |      word boundaries; n-grams at the edges of words are padded with space.\n",
      " |  \n",
      " |      If a callable is passed it is used to extract the sequence of features\n",
      " |      out of the raw, unprocessed input.\n",
      " |  \n",
      " |  preprocessor : callable or None (default)\n",
      " |      Override the preprocessing (string transformation) stage while\n",
      " |      preserving the tokenizing and n-grams generation steps.\n",
      " |  \n",
      " |  tokenizer : callable or None (default)\n",
      " |      Override the string tokenization step while preserving the\n",
      " |      preprocessing and n-grams generation steps.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |  ngram_range : tuple (min_n, max_n)\n",
      " |      The lower and upper boundary of the range of n-values for different\n",
      " |      n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      " |      will be used.\n",
      " |  \n",
      " |  stop_words : string {'english'}, list, or None (default)\n",
      " |      If 'english', a built-in stop word list for English is used.\n",
      " |  \n",
      " |      If a list, that list is assumed to contain stop words, all of which\n",
      " |      will be removed from the resulting tokens.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |      If None, no stop words will be used. max_df can be set to a value\n",
      " |      in the range [0.7, 1.0) to automatically detect and filter stop\n",
      " |      words based on intra corpus document frequency of terms.\n",
      " |  \n",
      " |  lowercase : boolean, True by default\n",
      " |      Convert all characters to lowercase before tokenizing.\n",
      " |  \n",
      " |  token_pattern : string\n",
      " |      Regular expression denoting what constitutes a \"token\", only used\n",
      " |      if ``analyzer == 'word'``. The default regexp select tokens of 2\n",
      " |      or more alphanumeric characters (punctuation is completely ignored\n",
      " |      and always treated as a token separator).\n",
      " |  \n",
      " |  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly higher than the given threshold (corpus-specific\n",
      " |      stop words).\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  min_df : float in range [0.0, 1.0] or int, default=1\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly lower than the given threshold. This value is also\n",
      " |      called cut-off in the literature.\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  max_features : int or None, default=None\n",
      " |      If not None, build a vocabulary that only consider the top\n",
      " |      max_features ordered by term frequency across the corpus.\n",
      " |  \n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  vocabulary : Mapping or iterable, optional\n",
      " |      Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      " |      indices in the feature matrix, or an iterable over terms. If not\n",
      " |      given, a vocabulary is determined from the input documents. Indices\n",
      " |      in the mapping should not be repeated and should not have any gap\n",
      " |      between 0 and the largest index.\n",
      " |  \n",
      " |  binary : boolean, default=False\n",
      " |      If True, all non zero counts are set to 1. This is useful for discrete\n",
      " |      probabilistic models that model binary events rather than integer\n",
      " |      counts.\n",
      " |  \n",
      " |  dtype : type, optional\n",
      " |      Type of the matrix returned by fit_transform() or transform().\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  vocabulary_ : dict\n",
      " |      A mapping of terms to feature indices.\n",
      " |  \n",
      " |  stop_words_ : set\n",
      " |      Terms that were ignored because they either:\n",
      " |  \n",
      " |        - occurred in too many documents (`max_df`)\n",
      " |        - occurred in too few documents (`min_df`)\n",
      " |        - were cut off by feature selection (`max_features`).\n",
      " |  \n",
      " |      This is only available if no vocabulary was given.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  HashingVectorizer, TfidfVectorizer\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The ``stop_words_`` attribute can get large and increase the model size\n",
      " |  when pickling. This attribute is provided only for introspection and can\n",
      " |  be safely removed using delattr or set to None before pickling.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CountVectorizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      VectorizerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, raw_documents, y=None)\n",
      " |      Learn a vocabulary dictionary of all tokens in the raw documents.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, raw_documents, y=None)\n",
      " |      Learn the vocabulary dictionary and return term-document matrix.\n",
      " |      \n",
      " |      This is equivalent to fit followed by transform, but more efficiently\n",
      " |      implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  get_feature_names(self)\n",
      " |      Array mapping from feature integer indices to feature name\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Return terms per document with nonzero entries in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array, sparse matrix}, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_inv : list of arrays, len = n_samples\n",
      " |          List of arrays of terms.\n",
      " |  \n",
      " |  transform(self, raw_documents)\n",
      " |      Transform documents to document-term matrix.\n",
      " |      \n",
      " |      Extract token counts out of raw text documents using the vocabulary\n",
      " |      fitted with fit or the one provided to the constructor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from VectorizerMixin:\n",
      " |  \n",
      " |  build_analyzer(self)\n",
      " |      Return a callable that handles preprocessing and tokenization\n",
      " |  \n",
      " |  build_preprocessor(self)\n",
      " |      Return a function to preprocess the text before tokenization\n",
      " |  \n",
      " |  build_tokenizer(self)\n",
      " |      Return a function that splits a string into a sequence of tokens\n",
      " |  \n",
      " |  decode(self, doc)\n",
      " |      Decode the input into a string of unicode symbols\n",
      " |      \n",
      " |      The decoding strategy depends on the vectorizer parameters.\n",
      " |  \n",
      " |  get_stop_words(self)\n",
      " |      Build or fetch the effective stop words list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf 적용\n",
    "- 단어빈도-역문서빈도(tf-idf) 적용\n",
    "- 한 문서에서 특정 단어가 다른 문서에서 보다 많이 나타날 때 가중치를 높게 주는 방식이다\n",
    "- CountVectorizer 호출 후 TfidfTransformer 적용, 또는 바로 TfidfVectorizer 적용\n",
    "> $ tfidf(w,d) = tf \\cdot (log({{N+1} \\over {N_w+1}}) +1) $\n",
    ">> 해당 문서 d 에 해당 단어 w 가 tf 횟수만큼 나타난  경우<br>\n",
    ">> $N$ 은 전체 문서 갯수, $N_w$ 는 해당 단어 w 가 나타난 문서 갯수\n",
    "\n",
    "- $tf$ 가 높을 수록 $N_w$ 가 낮을 수록 가중치가 높아진다 (즉, 이 문서에서는 자주 나타나지만 다른 문서에서는 자주 나타나지 않는 단어에 가중치를 준다)\n",
    "\n",
    "- 스케일 변경 후 각 문서(행)의 벡터곱이 1이 되도록 L2 정규화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_tfidf[0].toarray()**2).sum() # 정규화 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88396928, 0.88528918, 0.88514162])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train_tfidf, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84809215, 0.84473242, 0.85441671])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(BernoulliNB(), X_train_tfidf, y_train)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 열(단어)에서 tf-idf 의 최대값을 찾아, 이 중 가장 큰 값을 가지는 열(단어)를 뽑아내자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gloated', 'stormmatch', 'clotheslining', 'rollup', 'hardymatch',\n",
       "       'somersaulted', 'somersaulting', 'turnbuckles', 'brawled',\n",
       "       'rvdmatch', 'dudleys', 'hurracanrana', 'crossface', 'noblematch',\n",
       "       'ganged', 'tannouncement', 'riksihi', 'pinfall', 'wassup',\n",
       "       'chokeslammed'], dtype='<U74')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['blah', 'woo', 'lennon', 'sucks', 'bye', 'kibbutz', 'sasquatch',\n",
       "       'demons', 'zatoichi', 'colombo', 'botched', 'darkman', 'steve',\n",
       "       'wei', 'doodlebops', 'lupin', 'smallville', 'scanners', 'nr',\n",
       "       'pokemon'], dtype='<U74')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = X_train_tfidf.max(axis=0).toarray().ravel() # shape 가 (1,75911) 이므로 ravel() 적용\n",
    "indexer = words.argsort()\n",
    "\n",
    "fn = np.array(vect.get_feature_names())\n",
    "\n",
    "display(fn[indexer[:20]], fn[indexer[-20:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- idf 값이 낮은 단어 : 전체 문서에 걸쳐 매우 많이 나타나거나 조금씩만 사용되거나 매우 긴 문서에 나타나는 경우\n",
    "- idf 값이 높은 단어 : 특정 쇼나 영화에 자주 나타나는 단어\n",
    "\n",
    "\n",
    "- 아래는 여러 문서에 걸쳐 자주 나타나는 단어 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', 'and', 'of', 'to', 'this', 'is', 'it', 'in', 'that', 'but',\n",
       "       'for', 'with', 'was', 'as', 'on', 'movie', 'not', 'have', 'one',\n",
       "       'be', 'film', 'are', 'you', 'all', 'at', 'an', 'by', 'so', 'from',\n",
       "       'like', 'who', 'they', 'there', 'if', 'his', 'out', 'just',\n",
       "       'about', 'he', 'or', 'has', 'what', 'some', 'good', 'can', 'more',\n",
       "       'when', 'time', 'up', 'very', 'even', 'only', 'no', 'would', 'my',\n",
       "       'see', 'really', 'story', 'which', 'well', 'had', 'me', 'than',\n",
       "       'much', 'their', 'get', 'were', 'other', 'been', 'do', 'most',\n",
       "       'don', 'her', 'also', 'into', 'first', 'made', 'how', 'great',\n",
       "       'because', 'will', 'people', 'make', 'way', 'could', 'we', 'bad',\n",
       "       'after', 'any', 'too', 'then', 'them', 'she', 'watch', 'think',\n",
       "       'acting', 'movies', 'seen', 'its', 'him'], dtype='<U74')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn[np.argsort(tfidf.idf_)[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 계수 조사\n",
    "- 로지스틱회귀 에서 산출된 가중치값(w) 중 가장 양수로 크거나 음수로 큰 값을 조사한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(min_df=5)\n",
    "vect.fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (27264,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.coef_[0]\n",
    "type(w), w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst', 'bad', 'awful', 'waste', 'boring', 'poor', 'terrible',\n",
       "       'nothing', 'worse', 'no', 'poorly', 'horrible', 'dull',\n",
       "       'unfortunately', 'annoying', 'script', 'stupid', 'ridiculous',\n",
       "       'disappointment', 'fails'], dtype='<U20')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = w.argsort()\n",
    "\n",
    "fn[indexer[:20]] # 큰 음수값들, 즉 부정적인 영향을 끼침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['great', 'excellent', 'best', 'perfect', 'wonderful', 'amazing',\n",
       "       'well', 'loved', 'favorite', 'today', 'fun', 'love', 'enjoyed',\n",
       "       'highly', 'brilliant', 'superb', 'it', 'definitely', 'and'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn[indexer[-1:-20:-1]] # 큰 양수값들, 즉 긍정적인 영향을 끼침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26966,  1970,  1896, 26422,  2968, 18363, 24272, 16630, 26958,\n",
       "       16534, 18366, 11754,  7621, 25523,  1238, 21273, 23420, 20409,\n",
       "        6927,  8875, 23154,  1145,  6370, 12982, 23632,  3220, 11491,\n",
       "        8204, 14484,  9915, 24638,  9034, 14488, 26565,  1034, 26899,\n",
       "       17789,  2485,  8576, 10641], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[indexer[:20], indexer[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFACAYAAABz8IAGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XeYZFW1/vHvS5CgBMMoig6gImYQBkwYQEwkA6hwMWHAeIWf92K8KoarqKACXkVEEVFREbkgQQElB2EGiYIKXFBEBZQwKoiD6/fH2kWfrqlwqk5VV/fM+3meeaarunad3d1Vp9bZe+21FRGYmZmZmdnwVph0B8zMzMzM5joH1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKyhlSbdgWE86EEPivXXX3/S3TAzMzOzZdiiRYtuiYh5dR47J4Pq9ddfn4ULF066G2ZmZma2DJN0fd3HOv3DzMzMzKwhB9VmZmZmZg05qDYzMzMza2isQbWkjSRdXPl3h6S92h7zXEm3Vx7z4XH2yczMzMxs1Ma6UDEifgVsAiBpReD3wDEdHnpWRGw/zr6YmZmZmY3LTKZ/PA+4JiJqr6I0MzMzM5sLZjKo3gU4ssv3ni7pEkknSXpCpwdI2kPSQkkLb7755vH10szMzMxsQDMSVEu6D7AjcFSHb18ErBcRGwMHAf/b6Tki4pCIWBARC+bNq1WD28zMzMxsRszU5i8vBi6KiD+1fyMi7qh8faKkL0l6UETcMkN9MzMzM7MZtP77Thjo8dftu92YejI6M5X+sStdUj8krSNJ5estSp/+PEP9MjMzMzNrbOwj1ZJWB54PvKVy31sBIuJgYGfgbZKWAHcCu0REjLtfZmZmZmajMvagOiL+Djyw7b6DK19/EfjiuPthZmZmZjYu3lHRzMzMzKwhB9VmZmZmZg05qDYzMzMza8hBtZmZmZlZQw6qzczMzMwaclBtZmZmZtaQg2ozMzMzs4YcVJuZmZmZNeSg2szMzMysIQfVZmZmZmYNOag2MzMzM2topUl3wMzMzMzmlvXfd8LAba7bd7sx9GT28Ei1mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKwhB9VmZmZmZg05qDYzMzMza8hBtZmZmZlZQ2MPqiVdJ+kySRdLWtjh+5J0oKSrJV0qadNx98nMzMzMbJRmapvyrSLili7fezGwYfn3VODL5X8zMzMzszlhNqR/vAT4ZqTzgbUlPXTSnTIzMzMzq2smRqoDOFlSAF+JiEPavr8u8LvK7RvKfX+oPkjSHsAeAPPnzx9fb83MzMyWA+u/74SBHn/dvtuNqSfLhpkYqX5mRGxKpnm8Q9Kz276vDm1iqTsiDomIBRGxYN68eePop5mZmZnZUMY+Uh0RN5b/b5J0DLAFcGblITcAj6jcfjhw47j7ZWZmZjbXebR59hjrSLWk+0pao/U18ALg8raHHQe8tlQBeRpwe0T8ATMzMzOzOWLcI9UPAY6R1DrWdyLix5LeChARBwMnAtsCVwN/B3Yfc5/MzMzMzEZqrEF1RFwLbNzh/oMrXwfwjnH2w8zMzGw2GjR9A5zCMVvNhpJ6ZmZmZmZzmoNqMzMzM7OGHFSbmZmZmTXkoNrMzMzMrCEH1WZmZmZmDc3ENuVmZmZmyyxvwGLgkWozMzMzs8YcVJuZmZmZNeT0DzMzM1vuOYXDmnJQbWZmZiPTJDhturugA2ObJAfVZmZmNo2DU7PBOag2MzNbxjQd8TWzwTmoNjMzm4U8Wmw2t7j6h5mZmZlZQx6pNjMz62EmF955tNls7nJQbWZmyzQHtmY2ExxUm5nZrOfA2MxmO+dUm5mZmZk15JFqMzOrxRtzmJl156DazGw54sDWzGw8nP5hZmZmZtbQ2IJqSY+QdJqkKyVdIWnPDo95rqTbJV1c/n14XP0xMzMzMxuXcaZ/LAH+IyIukrQGsEjSKRHxy7bHnRUR24+xH2ZmZmZmYzW2keqI+ENEXFS+XgxcCaw7ruOZmZmZmU3KjORUS1ofeArw8w7ffrqkSySdJOkJPZ5jD0kLJS28+eabx9RTMzMzM7PBjT2olnQ/4Ghgr4i4o+3bFwHrRcTGwEHA/3Z7nog4JCIWRMSCefPmja/DZmZmZmYDGmtQLWllMqD+dkT8sP37EXFHRPy1fH0isLKkB42zT2ZmZmZmozbO6h8CvgZcGRGf6/KYdcrjkLRF6c+fx9UnMzMzM7NxGGf1j2cCrwEuk3Rxue8DwHyAiDgY2Bl4m6QlwJ3ALhERY+yTmZmZmdnIjS2ojoizAfV5zBeBL46rD2ZmZmZmM8E7KpqZmZmZNeSg2szMzMysIQfVZmZmZmYNOag2MzMzM2vIQbWZmZmZWUMOqs3MzMzMGnJQbWZmZmbWkINqMzMzM7OGHFSbmZmZmTXkoNrMzMzMrCEH1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKwhB9VmZmZmZg05qDYzMzMza2jsQbWkF0n6laSrJb2vw/dXkfS98v2fS1p/3H0yMzMzMxulsQbVklYE/gd4MfB4YFdJj2972BuBWyPi0cDngU+Ps09mZmZmZqM27pHqLYCrI+LaiLgb+C7wkrbHvAQ4vHz9A+B5kjTmfpmZmZmZjcy4g+p1gd9Vbt9Q7uv4mIhYAtwOPHDM/TIzMzMzGxlFxPieXHoF8MKIeFO5/Rpgi4j498pjriiPuaHcvqY85s9tz7UHsAfA/PnzN7v++uvH1u9u1n/fCQM9/rp9txu6bdP2k2o7yWP7Z14++l1tO8ljz9W/lZmZ1SdpUUQsqPPYcY9U3wA8onL74cCN3R4jaSVgLeAv7U8UEYdExIKIWDBv3rwxddfMzMzMbHDjDqovBDaUtIGk+wC7AMe1PeY44HXl652Bn8U4h8/NzMzMzEZspXE+eUQskfRO4CfAisDXI+IKSR8DFkbEccDXgCMkXU2OUO8yzj6ZmZmZmY3aWINqgIg4ETix7b4PV76+C3jFuPthZmZmZjYu3lHRzMzMzKwhB9VmZmZmZg05qDYzMzMza8hBtZmZmZlZQw6qzczMzMwaclBtZmZmZtaQg2ozMzMzs4YcVJuZmZmZNeSg2szMzMysIQfVZmZmZmYNOag2MzMzM2vIQbWZmZmZWUMOqs3MzMzMGnJQbWZmZmbWkINqMzMzM7OGHFSbmZmZmTXkoNrMzMzMrCEH1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBpaaRxPKumzwA7A3cA1wO4RcVuHx10HLAbuAZZExIJx9MfMzMzMbJzGNVJ9CvDEiHgy8Gvg/T0eu1VEbOKA2szMzMzmqrEE1RFxckQsKTfPBx4+juOYmZmZmc0GM5FT/QbgpC7fC+BkSYsk7TEDfTEzMzMzG7mhc6olnQqs0+FbH4yIY8tjPggsAb7d5WmeGRE3SnowcIqkqyLizC7H2wPYA2D+/PnDdtvMzMzMbOSGDqojYpte35f0OmB74HkREV2e48by/02SjgG2ADoG1RFxCHAIwIIFCzo+n5mZmZnZJIwl/UPSi4D3AjtGxN+7POa+ktZofQ28ALh8HP0xMzMzMxunceVUfxFYg0zpuFjSwQCSHibpxPKYhwBnS7oEuAA4ISJ+PKb+mJmZmZmNzVjqVEfEo7vcfyOwbfn6WmDjcRzfzMzMzGwmeUdFMzMzM7OGHFSbmZmZmTXkoNrMzMzMrCEH1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBoaS51qMzMbn+v23W7SXTAzszYOqs3MZpiDYjOzZY+DajOzITgwNjOzKgfVZjZRTYPTJu0dGJuZ2ah4oaKZmZmZWUMOqs3MzMzMGnL6h5k15jQKMzNb3nmk2szMzMysIY9Um80ik1x059FmMzOz4TmoNhsxB6dmZmbLH6d/mJmZmZk15KDazMzMzKwhp3+YtXH6hpmZmQ3KI9VmZmZmZg2NbaRa0j7Am4Gby10fiIgTOzzuRcABwIrAoRGx77j6ZMsPjzabmZnZTBp3+sfnI2K/bt+UtCLwP8DzgRuACyUdFxG/HHO/bA5wYGxmZmZzxaTTP7YAro6IayPibuC7wEsm3CczMzMzs4GMO6h+p6RLJX1d0v07fH9d4HeV2zeU+8zMzMzM5oxGQbWkUyVd3uHfS4AvA48CNgH+AOzf6Sk63BddjrWHpIWSFt58882dHmJmZmZmNhGNcqojYps6j5P0VeD4Dt+6AXhE5fbDgRu7HOsQ4BCABQsWdAy8zczMzMwmYWzpH5IeWrn5MuDyDg+7ENhQ0gaS7gPsAhw3rj6ZmZmZmY3DOKt/fEbSJmQ6x3XAWwAkPYwsnbdtRCyR9E7gJ2RJva9HxBVj7JOZmZmZ2ciNLaiOiNd0uf9GYNvK7ROBpepXm5mZmZnNFd6m3MbKtabNzMxseTDpOtVmZmZmZnOeg2ozMzMzs4YcVJuZmZmZNeSg2szMzMysIQfVZmZmZmYNufqH9eTqHWZmZmb9eaTazMzMzKwhB9VmZmZmZg05qDYzMzMza8g51csB50WbmZmZjZdHqs3MzMzMGvJI9Rzh0WYzMzOz2csj1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKyhsWz+Iul7wEbl5trAbRGxSYfHXQcsBu4BlkTEgnH0x8zMzMxsnMYSVEfEq1pfS9ofuL3Hw7eKiFvG0Q8zMzMzs5kw1m3KJQl4JbD1OI9jZmZmZjZJ486pfhbwp4j4TZfvB3CypEWS9uj1RJL2kLRQ0sKbb7555B01MzMzMxvW0CPVkk4F1unwrQ9GxLHl612BI3s8zTMj4kZJDwZOkXRVRJzZ6YERcQhwCMCCBQti2H6bmZmZmY3a0EF1RGzT6/uSVgJeDmzW4zluLP/fJOkYYAugY1BtZmZmZjZbjTOnehvgqoi4odM3Jd0XWCEiFpevXwB8bIz9majr9t1u0l0wMzMzszEZZ071LrSlfkh6mKQTy82HAGdLugS4ADghIn48xv6YmZmZmY3F2EaqI+L1He67Edi2fH0tsPG4jm9mZmZmNlO8o6KZmZmZWUMOqs3MzMzMGnJQbWZmZmbWkINqMzMzM7OGHFSbmZmZmTXkoNrMzMzMrCEH1WZmZmZmDTmoNjMzMzNryEG1mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKwhB9VmZmZmZg2tNOkOzCXX7bvdpLtgZmZmZrOQR6rNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk15KDazMzMzKyhRkG1pFdIukLSvyQtaPve+yVdLelXkl7Ypf0Gkn4u6TeSvifpPk36Y2ZmZmY2CU1Hqi8HXg6cWb1T0uOBXYAnAC8CviRpxQ7tPw18PiI2BG4F3tiwP2ZmZmZmM65RUB0RV0bErzp86yXAdyPiHxHxf8DVwBbVB0gSsDXwg3LX4cBLm/THzMzMzGwSxpVTvS7wu8rtG8p9VQ8EbouIJT0ecy9Je0haKGnhzTffPNLOmpmZmZk10XdHRUmnAut0+NYHI+LYbs063BdDPGbqGxGHAIeUPt0s6fpuj52ABwG3TKj9XGw7yWMvj/1eHn/mSR57eez38vgzT/LYy2O/l8efeZLHnqs/8zisV/eBfYPqiNhmiA7cADyicvvhwI1tj7kFWFvSSmW0utNjuvVp3hB9GhtJCyNiQf9Hjr79XGw7yWMvj/1eHn/mSR57eez38vgzT/LYy2O/l8efeZLHnqs/86SNK/3jOGAXSatI2gDYELig+oCICOA0YOdy1+uAbiPfZmZmZmazVtOSei+TdAPwdOAEST8BiIgrgO8DvwR+DLwjIu4pbU6U9LDyFO8F3i3pajLH+mtN+mNmZmZmNgl90z96iYhjgGO6fO+/gf/ucP+2la+vpa0qyBx1yATbz8W2kzz28tjv5fFnnuSxl8d+L48/8ySPvTz2e3n8mSd57Ln6M0+UMgvDzMzMzMyG5W3KzczMzMwaclBtZmZmZtaQg2ozs1lG0ip17rPJ89/KzFocVI9QKR/Y974RHm/TXv/Gddy2Pjygw7+Va7ZdQdIrx93HLsd+eYd/z5P04AGe477j7GOXYx4taTtJQ713Ja0maaNR96vGcfeT9IQJHPfTde7r8JhOr+t7/w3RjxUkrTlAk/Nq3tfvuPeX9ORB201C09eIpD3r3DcGjf5WkrYf9v08CpLWk7RN+Xo1SWuM+XgLJb1D0v0bPs9A598u5/x7//VoN9JzwYB9HsmxJb2izn1d2j6zzn1d2g79nmzS50nyQsURknRRRGzadt+iiNisR5vL6L2TZNcPREmn9ehORMTWvfpbeZ7HAF8GHhIRTywfwjtGxCdqtL2O3OjnVnKXzLWBPwA3AW+OiEV92p8ZEc+u08+2dg8BPgk8LCJeLOnxwNMjolZZRkknkKUgW7/D5wLnA48BPhYRR/Ro+wzgUOB+ETFf0sbAWyLi7TWPvRawD/CsctcZ5Zi312i7DbA78DTgKOAbEXFVzePuAOwH3CciNpC0STnujj3aHETv1+e7ah77TaXfKwGHAUfW+XlL23d3uPt2YFFEXNynbaf35KW93lflMf9H/twC5jP99f3biOh7sSzpO8BbgXuARcBawOci4rM92qwDrAt8C/g3pnaeXRM4OCIeW+O4pwM7kr/ri4GbgTMiotPvsdqu27lI5Pmk17locZe2kI37XlA0eY2U9p3+1r+IiKfUaPtA8j35TPLnOJt8b/y5R5vGf6vyPN8iz0VHA4dFxJU12gz9udH2PG8G9gAeEBGPkrRh6fvz+rRbBdgJWJ9KFbGI+FiNYz6a/Du/ClhI/q1PjprByLDnX0mHlS8fDDwD+Fm5vRVwekR0DKzbzgXtIiIeWbPfP2Lpv9nt5O/gKxFx1xiP3em9sdR9M9S27nty6ONOUqOSepYkPRZ4ArBW2xXvmsCqfZpvX/5/R/m/FcztBvy9V8OI2GrArnbzVWBv4CvleS8tAUHfoJqsQ35MRPwEQNILgBeRdcq/BDy1T/tTJP0n8D3gb607I+Ivfdp9gzwZf7Dc/nV5jrq1zv8FPC4i/lT6/RDywuKpwJlM/R06+TzwQnKTIyLiEkmDXBh8HbgcaI3Sv4b8WbqOlrRExKnAqSUw35X8/f2O/Bt+KyL+2aP5PmQJy9PLc10saf0+h1zYr091RMShwKFllHx34FJJ5wBfjYheF4cAC8q/H5Xb2wEXAm+VdFREfKa9gaS3AW8HHinp0sq31gDOqdHfDcrzHAwcFxEnltsvBuruMvv4iLhD0m7AiWRd/kVA16CafF29ntxh9nOV+xcDH6h53LXKcd9EBmkfafsddLN9/4d0FhFrAEj6GPBH8v0j8jxWa+Rz2NeIpF3JoHYDScdVvrUG0DUobvNd8n2/U7m9G3k+6fW3HsXfioh4tXIWY1fgMEnB1EXF4i7Nhv7caPMO8pzw89KX36jebN2xlAtb4B8DHI+IuBr4oKQPkT/H14F/Sfo6cECNc/9Q59+I2B1A0vHke/MP5fZDgf/p0W5Us83XAvOAI8vtVwF/Igdyvkp+Doz02OV8tS2wrqQDK99aE1jSp+3TyYuPeW0DG2sCK/ZpO/R7skmfZwMH1aOxEXlyWBvYoXL/YuDNvRpGxPWQ0ykRUZ1SeV/5QKlz5f/aLs/9zX5ti9Uj4gJp2sVw3Rfvgoh4a+WYJ0v6ZES8W/XyCt9Q/n9H5b4A+l2BPygivi/p/eW4SyTdU7PPAOu3AuriJuAxEfEXSb0CU8rxftf2+xrk2I+KiJ0qtz8qqeeIa1UZVXs1eRL+BfBtYEtyV9Ln9mi6JCJub+t3TxFxeO0H9yFpReCx5d8twCXk5k9viYhdejR9ILBpRPy1PM9HgB8AzyY/1JcKqoHvACcBnwLeV7l/cY0P7arN217fJ0n6eM22KytToV4KfDEi/lkCpq7K7/twSTtFxNED9LNqpRIovJKpi86+Wueihl4YEdUL6S9L+jmd/0ZLGfI1ci45O/YgYP/K/YuBOhcTkCO11b/rJyS9tFeDEf2tWs91h6SjgdWAvYCXAXtLOjAiDurw+MafG8U/IuLu1jlB0kr0GAGveHhEvKjmMZainA3dnQyejmbqHPYzYJN+7Ruef9dvBdRFK7Dt1teeI6MRcVHN4z6lbVb2RyoztZKu6NWw20VDRJzZ55g3kgMjO5LnypbFwP/r0/Y+wP3IOLF6YXwHUzthd9PkPdmkzxPnoHoEIuJY4FhJT4+IgfMei/tK2jIizoZ7p7jq5oxtXvl6VeB5wEVA3aD6FkmPopxMJe1MviHq+Iuk95IjPZBX37eWD8d/9Wvc4Er8byW4bPX5aeTISV1nlRGLo8rtnYAzlXl6t/Vp+7vy9wlJ9wHeBfSdsq24s+1v/UzgzjoNJf2QDDiOAHaofDh8T1K/UeXLJf0bsGKZ5n0XefLrdbxOU5b36pU60vY8nyNPkj8FPhkRF5RvfVrSr/o0nw/cXbn9T2C9iLhTUsdRspI2cDuwa/lQ3LL8HOcAgwTVt0j6L3KKP8iLmbqjn18BriMDwzMlrUd+INVxfPlbrc+A0+tkQPUT4OyIuFDSI4Hf9Guk7ikcrfSPOjnh95SR+e+W59qVmgHPsK+REmBeT6ZQDOs0SbuQM2yQQcMJNds2+Vu10rLeADyKfF9vERE3SVqdPK8sFVRXNPncADhD0geA1SQ9n5zd+VGfNgDnSnpSRFw2wLEofVxEnmO/BrwvIlrv4Z+rXq5u0/Pv6crdn48kX6O7MJUG2Mn+Pb4XQK00S3LEd35E/BZA0nwy6ITp57dO9q58vSo5u7Co37Ej4hLgEknHAH+LqZ2tVwR6DnpFxBnk6+MblYu4Fci0m57nsSbvyUqfv9Nn5nVWck71CEn6DJkycSeZFrExsFdEfKtG283IabC1yl23AW8Y4Cq4+lxrAUcMEPA8ktzB6Blk7uj/AbvVGbmS9CDgI2TQIjIX8aNkQDO/TPX1ar8y8DZy1BEyNeEr/d5MJVA6CHgimUoxD9g5ImqNTCmHOXYicyhb/T46arwhys98ADk1LOBkYM/okX/Z1n4T4HCm/ta3Aq+r03dJW0fEz/o9rkvb1cmRyxeUfv8E+HinXL5Km+f0es5y4q1z7DcA342IpaamJa0VPXJnyzTxy8gpZ8jZoOPID7tDImK3Pm1fCfyw3PVS4KiosV6gtH8A+fpuvT7PBD464Gh39flWioi+s0CSfszU9Pq9QWlE9PqAnzhlOtEBTOUmn0OeA6+r0Xao14iksyNiyw4XBX0vBiptRAajrd/1isBf61xINP1bSfomcGinUUdJz4uIn/ZoW/3ciNKP2p8bJUh6I9PPCYf2Ow9K+iXwaPKz4h/UyLuvtH1k5G7KQ+ly/n3XIO9JSS+j8p6O3B16rCRtCxwMXEP2ewPyIuZ0cv3RFwZ4rkcAn4mIXWs+/nxgm8ps3/3IPPZn1Gg78NqQStuXA58m89jFABfoZeDnU8DjqaTRRs088klxUD1Cki6OiE3KG/al5FTFaRGx8QDPsSb5dxlk1LX9OVYGLo2Ix9V8/AYR8X9llHaFiFjcum/YPtQl6VBgZTLIhExpuCci3lSj7Upk6o2AX82Vq1plWszO5MjU2uQHYfQa2VKP1elk4x/2+v6kjGrqVNICKhdAEVEr11vSleS0613l9mrARXXfG01I+nCn++uMYEq6PCKeOODxGi0qlbRmSUPoWFVg2AuJfkY4vT7s8QU8ojWCOET7gf9Wozbs50b5rDqxMlpct916ne6vm0IkaTtyHVI1WKo7sv/MiDin3319nmM9YMOIOLUMNqwY3fPXW21WB95NDhbtUYK+jSLi+AGOuwo50yjgql4DGn2eR+Rn/JNqPv7iiNik33292pYZqM0oa0NqXkBdTc6oDjKT0Gp7Njmg8XlyIGV38jX+kUGfayY5/WO0WqXktiUXmfxFA+SvVk80rXY1P4CrU/QrkFd23+/eYilHkzmrf6vc9wPyDdTv2I8B/pOlpz7rTolt3nbR8TNJl/Q4Xrfg8jGSageXDa+gh56RKI4lZyIuAn5fs80OPb4XTI3ELkUjSOHQ1Cr09rb9Rg1GNXX6CzLXbqXSn/k1g6DryA/u1ofXKuRIUU+SvhARe3X73dWcBaq+n1Yl113U/XAZZnq96aLS75B9XMTSFQfqrHNA0jxyHcn6TD8fvKFbG0b3GhlKRESZHu97vutiqFSIbiPrDHYualQFiUy3+YKkM8mUnZ/UmUmhx/mkH+Xi39XJqhuHkgMMF/RsNN1BQPuFWKf7uh3/3oon5MDGuuQIcs+KJ+Ti0UXkjC7ADWT6YO2gmnyNrU++N55cPrP6pmm2XTCvQOadd/2c7OBvkjZtXaCWGY5aKYcMsTak4k/DBNTFahHxU0kqF2v7SDqLDLRnLQfVo3WcpKvIF+vbywdMrSvRYU40klYpIwz7Ve5eAlwfETfUOGaTqiUtR5EnpEMZbLFIyz2SHhUR15Q+PbLP8wwdXLb5DENeQQMviIj3lFGeG4BXkDl5dYPqgRf5RMTuZap254gY5IIJpr8+hrWg8vWq5M/ct05qjKBCjaR/J0+kfyJfG63go07ZsH8AV0g6pbR5PnC2yqryHqO3rWoKQ//u2qf/Je1HqVhQw5bA68vFTK3p9Wi4qDQiti//N6k4cCxwFnAqNc8Ho3iNjMD5kjaPiAuHaDvw3wqmKqY09A0aVEEq55WVgReT1Rq+JOmUGjOFJzB1AbAqmcrwK/LzpJ9nRMSTlaUtPyppf2qct9WgGkWbYSuePCoiXqWsbEHkmo7ao2aSjiCD+IuZem8E9dY+VS+Yl5CDdrVH5snFr0dJurHcfii5/qmOJmtDFkr6HvC/VKrE1Bz8uqt85v1G0jvJAaja+0hMioPqESl//B+3ZuHBAAAgAElEQVSRwdodEXGPpL8DL6n5FMOcaM4jr87fFBFLleOpYeiqJRVLIuLLQxy7ZW9ykdC15Al6PXKap6MoZZFGoMkVdKMZCYYc2YqIf5WTy0BBdVTynpULex5Lnsx/FRH9Fsi0nqM9X/wLZXquY4pDu4ZTp3uWx9ZdIFh1TPnXcnqdRlHqq0fEGcP+zjpYnRqjvcWLB33yEY2uI+mn0VanuNN9XaweEe+t1+Oljtt4er2BrcgSjdeRMwy1c4QZ4m/VTrlw7CFMH92vMxPTtAoSZeTxJPI1sxr5mdUzqG5POygpPG+pecjWCOnfJT2MXPhb50KuSTWKqmErntytTB9rLY5/FIOVE1xAlvKrPcpfed89ftj3FUDkguXHMpUueVXUTJeMiAOBamm76yXVvRBekyzx+ILqU1Jv8Gsv8pz5LuDj5Hv0dTWPOzEOqkekBDz7R8TTK/f9jelTwL0Mc6K5j6TXAc/olBbR72owRlO15EeS3k4GLtUr0Vr5l2V6Z0Omv9n7nqiUlT9aCyRrbdbQpskV9NAzEsVQI1vFsHW9W+lF0xbKKEuVnVSjbXVqdQXyA2KQkbYmU6e/Y7DKLvdqOnrb8HdW3aBjRXIxba280Yi4XtKWZN7nYeU1dr8+zRqNrktalfwQe5Byt7vqZiYPq/k0x0vaNkpd7wGNYnp9WEMHxjFVGeHB1J/hu1fbTEyrYlLdmZhGVZAkvYisfrEVecF5KFP182uLiIskbd7/kUC+RtYm67VfRPb90BrHWKoaxZDO0HAVTz5Cpvs9QtK3yTUerx/guJcD61C/shbAQ5WLxXeU9F2mp2QNsialdcG6XkS8WdKGkmpdsKpLihE1ZkOaDIK1Zo0y+2Nkg2lj54WKIyTpo2QNxh8OcjVa2n6IzAvbmqlC9IdGxId6tNmSLPb/SpaeVo4+eYzV52lStaTTYsaI+js9DVv94xSyEkOrj7sBz42IWhtzaGp3rfZ+9/ydlRmJp5G5sa0ZifsCa0TEH2see+hFPk1+3+VCYPsoFVnKSMsJUW+XvtOYChCXkNOB+0XEr/u1Le0XRsQCVXbTknRJ1FjEK+lr5EXXCUy/APpcjzbfj4hXqsvOczUvYJr+zqp/5yXk7Eit+u/KWtwLyJHax5QL7aNiek3ikVJuH7wXGUD/nqk0m8VklZWuG2RUnmMxWUXjH2Tpw0Hyg4d+jYxCp4uYqLFYW9KOZF74w8h69+sBV0ZErS3XlYu5njrMTIwyN/ZAhq+C9F0yl/qkOoMZlXbV9IsVyFzhB0TEC+s+R3meVYBVo95usqOaiRm24skRwGXk5+S1wM8j4pY6xyztTyNzoS9g+nms1462O5e+bsnSayYi6u+a/D3ygvW1kbsmrwacF/UWKp5ESTGKiI3LyP4v2mcrurRtsltzK3AfaufiSXFQPUKVD5R7yDfeIB8oq5HB5bPIE8ZZwJejxupgSW+M+gtTOrVvXLWkwbGHqv6hDtu/tz6Ux9PTacc5rzojMVeobUt45fznGdFjm/jKh2d1ERXl656BbdvznEsuBDonIjYtwemREbFFjbYdF6ZExEd7tHloRPyhyQVMeZ6Bf2dt7Tdmajv6MwcIdi4GnkJWKmkFmH23Vy+Pa1SKSlm15AuRlUA+RKaYfXyAUbEHABu2Hbtv6cUmr5GmmlzEKBdWbw2cGhFPUU6N7xoRe9Q89mnA8+tecHVo36gKUhmJbI0yXxARN/V47BER8RpJt5FVGWDqIvvoXp9XaljBSNJmEbFIXcp81nmNlecZtuLJ1mRw+ywyjeti8j19QM32Q/W7nHM+FDWro3R5jiaDGhdGxOZtbetWDjmDsltzpW2tajnKTaN2Jne0HajtJDn9Y4Si2cKTw8kRoVbu0q7kAoY6U3GvVy7wO4v8QOpZGqiDgXOEVeoldztR9jtBVgxU/aNiqM0aJL0nIj6jLuXHok/ZseJkSTsxxIxEU8OM7Ff+RldIOpH8nQW52LDfwqzWa3oj8oP3WPLDewdypqCufVh66rTWlF6v4LlHmz8o81S/Vnf2oouOv7PW77TX67yM/L6ZqfzBb0s6JDrskNfB3RERKqvsy2xIXYcxVYpqK0opqgHa7xwRHysjt88nR2G/DDy1dzNQbo2+J7l198XkrE4rWO5nH4Z8jYzAyygXMQARcaOkuufzf0bEnyWtIGmFiDhN0qf7NapcsF5LbkhSeyam8hwLyTrVR0bErTX7W23/CjJd6HTyNXKQpL0j4gddmmxWLlR/y9Kb0qxO7zS41rqdB5MpPq16+63Uk37piovKe/rNEfHqXo/tY6iKJ+Xz7gzyPLgVWbv5CWTN7L7qBv0d2oWkl1B/l8xOmuSDN0kxarJbc9OdMyfCQfWIlanAewOeqL/IZqO24PK0msElZPL+luRmJp9V7jJ3VkTU3dLzRxo8R/g55EmxUzWOQapwDFT9Q9M3a3g3U3mkKwJ/pX+5ndbixCblx95NmZGQNNCMxAh8mbwI+lK5/ZpyX6+R/erf6E/k3w7gZuD+vQ7WCmglnUyWXVxcbu/D1G6UfUVuX7+IDLJEbpbTc+q06XRvlMXC6rO5TB+rsvTv7AHk77Tf6/yN5LT+3wBKoHUevXfIa/m+pK8AaytLgL0B+GrNPjctRdV6/20HHBwRx5a/dx17kkHH+RGxlXJxVK2LomFeIyPU5CLmNuVmGmeSF043US9waAXtvy3/7lP+DWIX8sLjwhJgH0Zu6lH3Yv+/yIGNmwDKuf9UsqRqJweTFz4bMP0c2prJ6jobEiUvVrmT7eOj7AYr6aFMpTz2VN7T8yTdJ4ZcMBxDVjyR9FPyvH8eOYB17++tT7uhNyeqaFKdBprlg7+bTC99pKRzKClGNds22a256c6ZE+H0jxGStC/5gfLtcteuZJH099Vo+w3yA+z8cvup5C57tfKHyonpOeTU1FbAb2OAsm3KhUmtHOHVgTWjT46whi/xVn2O55EfBK0dttYHdo+I04Z9zmVZpym7utN4DY97FbBxa8pUmQt5SdTILS6PH7iixCimeyV9nwzSTmH6ws46MxKNKPO5N4+pjWdWBS6M+hs2PJ9K3mdEnFKz3TnkeeAH5IXv74F9I2Kjmu2PL222IXNl7yTTAgaZKr6YvKD4xwBTxU2qjjSiXPy7ITky/ynyIuY7dWYVSgB+F/l32o3cce7bMVy1mqGUc/H25AX2v8jR6wOizwJmSZdVX4/leS7p9xqV9OWIeNuQfZ02hV+OeWndaf1ysbkpGehV39O1UtEqz7My8CLyouRZETGvz+M/T74f/kHuFHommZdct97z0JQ7WG5EptnUrk6jsilOOV/fj6kL1vPrXrCW89Y7gReSs+nnAQdFvdTUTrs1vzrq7bDaaOfiSfFI9WhtC2wSEf8CkHQ4uWlF16BaUwupVgZeK+m35fZ6wC/rHFTSNcAt5OYNXwP+vdWHAawLPL+8gVp61s+MIUu8tTmHrIPZ+uD8Cvmm7UjSYyPiKnXZhS3q53022rSmwYxEU4PW9R5VyssRwAXKTTKCnC7vW1lDDSpKRClrR47onTjEaxoyJahvWlA3ygWtnX5ndRYBHwb8vPzOINcr1F77EBGnKPMKWxvePKBXkKSS70qm6FRLUW3NYKWoXkkGG/tFxG3lgn3vmm1vUFZ2+F+yUs2t5KY9XTV5jYxKROxXLmLuAB4DfLjuRUxM3zRr4GozXWZibidHgr/SL3hRLv7anfz8OZoc1NmSvKDqdzHzY0k/AY4st18F9K3cMmxAXZxeOWaQo+2DDKLcWP6twGAViADQkBVPWjO/ZVZid/L9vQ65oVSd436NDEYvrty3T0TsU6P5sNVpDiQvBM6LiE0Z7lz4TfJ98clye1fy8+AV/RpGbke/jSq7Ndc5oDLN5zURsdsQ/Z0oj1SPkKRLyQoUfym3H0AGXF2vJtVlIVVL1KsIsSd5En0EcBVwBrmAou/OcaX9R4DnkgubTiTfwGdHRN8pHuVCpjsZosRbaf998g1bHd2/f0R0fMMqc1L3UC7uaRcDBMWXkFOZi6gEpZVArlfboWckmmob2b+3rnevkX1JO0TEj5TlF5cSNcvOlQuZ6qK7X9Ro06miBOTf/KsR8cUaz/EtsoTT0cBhMUB98dYoYkTcU26vCKwSEX+v2X6nys1VyYuJG+uOdJff2Zbkz13rd1bavYXMobyTHHlsjUx1nV4vo1kvJkfwngtLld8ayzbjPfrzHHLU9se9purbXiPVALz2a2QUJK1DbgoS5IxCv5m6UUzrI+kAckq9Gtj+kawZvWb02INAmS5zG3mxdnRUFt9J+mFE9FwcWB63E5kO0HqNHtOnSWPKxYKtQYmhjqnMeY+I+OuA7YatePJO8vy3GXA9OVJ9VkT8rGfDqfY3kINfn2+dcyVdVILdOu0Hrk4j6XwyZWI78meeps55bJjZUU2vDrOUOrMKkk6PiOf2e9xs46B6hJQL5/ZlatHHs4H3R8RSL+YxHb91Bf2f5K59tXaZKqPlG5NlcjZWrgY/NCJ67V7Yatu0pN4wb9gVyK14B9lRqv05lqoeMkDbS5k+I7Ei+burVaatqTKVN2hd7xXJFIC6I44jJenf60yl92i/JnnxsjsZwBxGLs7qOfJRPlS2aX3wlvfIyRHxjF7tejzfCmSVh64Xb+Viuqs6wa2k35Cv8UFKdr2LXMT6SKaXxOsbkM8GTV8jDY/9JnIjo5+Rv6/nkHXvvz4Dx55WYaZ6n6QrokdpPkmPLKOBc0r5jGldwPSsONKh7RPJkdLW++wWslTcFQMev1bFk0qbvclAelEMUalF0kXkxe63yRz6PcmLt6fUaDtUdZqSQrEN8Gk6bNRVZ0BFQ6SmqkvFpspx+66zkPTf5EV5+4BdrdnoSXH6x2htR+ay3Uq+ad7bb7RjFJS7Lz6LqUUUHyYXUtR1V0nlWFKCl5uoufNbNNvSGOAXkp7W9obtGSyXvu5Hjl4OpBLwNNq0htyFsvXYtQbtx7CUeYBvoZJ6IqlvXe/IXPmhLiJGISIOKh+G7WXe6mzRS2R5t6PJ0bu9yBHjvSUd2CcQW7U6khURf1WuGRjWhsD8Po9ZRIfyg9B/MVfFNeROZLVF2flMDfJdJ0GlkhDwew2xidWI7A08JUq+prLawbnk+byjUVw8FfMkzY+yg6Kk+cCDyvf6Lcb7s6TPMXU+OIO8GOi5MLfD6Pq932LMi64lvZLc+OX0crx+FUfaHQK8uzU7J+m55CLeWhfKGrziCQAR8dma/et66Ii4A9hBufD3DOp/dgxVnSYibpF0FLlxy0CpSWqQmlonaK6h9fdsPVfr/FlrNnpSHFSP1mHkVO+OlDqWZcShVsmdBs4nTxLzmcrvejhTi//6uVCZB/lVMiD4K1mgvi8NuXlLxVOZesNC/gxXtt7QPUZ/hy1r1x7wVEdu6wY8nwQuknQ6lRmJAfrQxDDVP1p+Iek4smpH9cp/7EFLtxQj+uTtl7Y7kAvHHkWOUG0RETeV4PhKelfT+JukTVujG5IWMLV7aZ1+twcffwR6bhc8ggtNyNfTucqc6upFX9/p2rkUUBejqiTUxA3kIqyWxeROnr20n0uq6p5LAP4DOFu5NkbABmQVpvvSP0f76+SmL62c4NeQn0P9akI3Kf/a1AcZrOJIu/tW090i4nQNVq1l0Iono3LvBm0RsY+yWkvPNImKoavTlAGVHYCBFnKSC1+HIunAXt+vmT53PEsPTtwhaZOo5KXPNk7/GLEyzV6tY3ln1KyQ0OCYbyYXJVVrw57Xa4q6rf0RlPwwchX7mlF/k4qhNm+ptB8qp1xTG+0sYWrl/SB5jKtG2wKgTvd1aXsE8BumZiR+PhMzEuXYQ1f/0JC7SI5CwxSjb5bHLlUXW9LzIuKnPdouIKcPbyRPyg8DXhU1cuebktRxg5hOP0eHtheQFx2XMbV1deNt162z8hp7ErnIM4CXkAMLv4bBK0sMcfxVgMcyldLV9zxU2i1VWaXTfbOJhqw4Unn8MeSIbauc6quBBRHx0pk4/iSoQXWa0n5GUynUZf1O5bh10k6+Q6a8HEe+L7Yj91V4LJn68pkRdHXkPFI9QhqyjuUIvIsha8MWrRH2gxh8hH3YzVuAegsx20kS8ITWdOmQziXLMvW7r5NJzUjAENU/yuNWJMtWfb7fY8fkzgYpRq+V9BBJrZGTe3MgewXUxQbktOl8cgr1aXSe9u5Izcq8VWdBViVzSBdRb/pySUTUHcVaJpTAcieWrsjTZNOLuq4p/1qOLf93HdFVlwpELf0CFnXfQOuRkurOIN0pacuIOLs85zMZYCZmQk7SEBVHKt5Afr79kAy2zmCwTYKGqnjSlHLTlIOAx5H1yFcE/hoRfVNAYnp1mo0YoDpN0UqlqL6XxpZK0R40S7pvTK+SU8cDyb0RWuthPkLOJjybPI86qF4OXEquDH4iWRLpNuWW1uM+yd0VEXdJQtIqkSXnatWkBZruFDVUkNdEmQY7hvxdD0S5wn9dYDVJT4Fp5btq5do2/H01tTe5MdC0ut79GpUpwB2Z2lp4pi1skGI0VA5k8aGIOKocu/bugBpBmbf2UXhJj6D+B8FpkvYAfsRwOf9z0bHkeXMR9Xd7G4khc0D37/WU9A9Y2tNe2nPv6wTVbwMOl7RWafcX6m/qMSlBlk5tVcU5hLzYrWv9mukDnQ8esbemVzw5JGag4gnwRbKU31HkCOxrydHnWkoQPUggXW271TDtmpL0dLIyzf2A+ZI2Bt4S9fbfmM/0NQX/BNaLiDuVG9zNSk7/GANNr8KxTkTUqmPZ4HjHlOPtRZ7IbwVWjohta7ZvH2E/u+4Iuya0eYuk/wG+EQPuMFWmpV5PntSqO4ItLs/X94Osye+rqRLs/QdTdb1PIUs01UlbmRWrqSWtz2ApRpcAz2/PgayZ8vKLiHiKpE8Bl0XEd1r39WnXqRRgkK+TQyKi1g5wbc8pcrag7zSzGlbVmYvUtinIDB/7NDrXIx/7oqjynm4foY9BRujL7A+RC+FmNXUoIyfp0qhZPan8rR5KBqffjQGqfkySpIURsaD6s0o6N3pUIlL3BaUADJDu+BByLdDDIuLFkh5PVheqXTd/GMo1ITsDx7XOuXXf58pyvS9jatZoBzIVZH/yHDwra1h7pHqEtHQdy68zWBWOoUTEy8qX+5QTzlrklqR1NRlhH2jzlhHaCnirpOsYYIepMi11uKSdIuLoIY89qRkJmCrE//Fyu3YhfmZ4CrCdpHXJleOtzUyeXSe/mNw0oHrR8mdy44c6fq/cgW0b4NMlxaBv25LKc4CkDwNfiKw+8iEyPajW61vTN9tZgdyIo25q1OM65fzXbDtXnSvpSRFx2QSO/Z+Vr1tBbs+yaT3SN4CBFgD/L1lr+iJyfQj0SVGS9OqI+Jba6gHndRtBjlgfFxG31uzD2El6G/B2Mr2lekG9Bn0qPlWVFMd1yMWZh5QLiu9FxCf6HH9iFU+Kvyu3275Y0mfI7bp7LjiMsqBU0sfIRdJHlP7uxmAb33yDHPz6YLn9a3JwZaxBNUBE/K68LltqzWRHxMclncjUjMZbI6I1EDYrA2rwSPVIqWEdy0kbZoRdA27eMirqssCxbo52SQf4MAOWomp7jhmdkSjHnMg25U1J+jSZu/hLpk6qERE71mj7WeDJTM+BvDQielbhKG1XJ3cHvCwifqPcHfBJEXFyzX5fGhFPVm688ElylOQDEdEzfaS0rS7WWQJcFzVrq3cZzau9UcRcpNy85tHkVsb/oOaF8hj7c0ZEPKfH9z8aER9RwwXAw4zQS3pLRHxF3esBP5CskjNIWsVYlRSV+5ML7aobZS0eNq1J0pOA95CLj+/TvJfjUz6zbiIX9v8/cvDrSxFxdY22P28/53S6r0f7CyNi8+osnWZgQaukH5BVR75Ipvi8i1xUuss4jztJHqkeoWhex3IiGo6wb9QW0J2mARYqDisirleHHaYGeIqvMUQpKpjcjEQxcF3vlvKh9hEaXEg08FLytTJwLlyTHMjInRN/WLn9B3KEqK7WBcB25AYIxyprzNbxA9p2c5S0evTYzVEjyPmfw4bdirkxTa85vQKZHrZOrzYloF6B3Jnv+w0OP/AIfUR8pfzfNRe8jG7OGuU8czs58DI0SY8jL6x3JmetvkumxM1qlQGfOxmskADk2qXdyJ81yN/hIGuX/qasvd4qyfc08m8xbm8l1xqtS5atPBl4xwwcd2I8Um2NRtg1xG5Lo6Ahd5iqtB+6FNUkZyQkXUmu/p5W15ssu9ZzVE+5ecrlTC9/uHHU2Mq4KUknAa+IAbcUnjRJx5M51duQF1F3ktVH6uRzD7ybo0aQ8z/XSFqzpNd03Exl2FHMAfvwf0zVxP0ncB15wXl2jbZL7YhY85itzTVWIhesXcuAI/RlMOHNLF0xZexlMielvK+OJM/3N/Z7/GyhrF70caZS4GqnnSjXoRxADiwEOZCyV0RcV/PYm5KVR54AXAHMA3aOmutarD4H1TYUTd9tqRXk3bvb0qDTmUMc/2LKDlOV6axBFrucB+wd00tR7RcRA+/SOJO6pb209Ep/aXIh0VQJ6DcGfsqAm5mUnNVPAw8mP4hmKgeyUfpIwwu3Jjn/c4qk4yNi+7bAtiViBhZnKnf5+3Fb7vzHo8Yi3vL4O1l6AXDPi4Em7+XKc5xLzpItojJyuby8duYSSVeTM6GXxQwHXmU9xjuBF5IX6OcBB0XNeugNjns4sGdE3FZu3x/Yf1m+6HP6hw1r6N2WRmToHaaKaikqyIopPQvWzwZ1c8a7mGRN2+Oo7Cg2oM8AO0TElSPsTy0N00fad3NsjXTXcbykf2MyNZtn2r7l/6UWZ86g/4qI75eUstqlF4s3kBcD7bNzPS8GGr6XW1avs7ZgWSJpQzIv+/HkolIAZuLiq6HfAZcPE1CPYEaitcD9k+X2IAvcm3hyK6AGiIhbS1rbMstBtQ1lRB8ITXxfWdVhbeWOkm8gayDXdSUZrD0KWJvML3spWdljWTWxC4lothPgnyYRUI/AXsBRklpT1A8lc0HrmFjN5gk4gEytqbv50jg0yZ1/PBlQb0kG12cBB4+8h50dL2nbiBj75iWzyGHk2pDPk1Wgdmf67MZs9R7gROUeB9XZujq7dR5Lvq5OZbh9ICay9glYQdL9o1ShKSley3TcuUz/cLZMm0cuBLt3hyky77WuY5kqY/X7kfdudprYhURlan+amqNLCyV9jyw9Vv0wmtX5xRFxoXJ3043g3u2n/1mz+cMj4kXj692s8s9SQePhkg5s/2adFKERGKr0YnE4eR5q9X3Xct8ru7YYnT2B90u6m8wFn7HUqAlaLSJ+KkllcGcfSWeRgfZs9t/kplerkjsqDqLpjMTQC9wb2p9ciPsD8vz/SvL3sMxyUG1z1fPLSebeHaYk7Q/UPfEsT0FLyyQvJBZUvl6VnHbsuDCtgzWBvwMvqNxXd8e5Gafu9Ys3VP3tpydZs3mmbU8Gs1uTI/OT8Eoyd36/iLit5M7v3adNy6RGASHLsu0GbBARH5M0n5wRWZbdVaqu/KZUYvo9ud5itntARLyg/8M6ajoj8VTgtZKmLXBvrY2quxZpUBHxTUmLyBkFAS+PiF+O41izhRcq2pyiygYCwDWVb60BnBMRr675PIeQCzWWh6AFGK4e7jhJOjsitpx0P0ZNI6hfrFlWs3kmSNo4ImYqGB2ZSVVAKsf6Mln5Z+uIeFxZCHZyRGw+7mPPNElHRMRrJL0H+BI52/Zx8sLiM63f/2wlaV/gZ3UWOXdou5jcKKY1IwEDzEiMYlHsMCRtExGntt33uobpgLOag2qbUzSiDQSW06BlYhcSpaRTS6sO8NuiXmm65bFsWKPNjeYiSY8hFwc+JCKeKOnJwI7RZ6e8SZl0BaTSh4siYlNN39Rj1m8GNYxyzn4xueD5ubTlUQ9y/p+ESmD8D5aTVB1JZ5Il/P6DHPg6FPhHROw80Y6NkdM/bE6JEW0gwAQ3mphpbfVwd5c0cD3cEdi/8vUS8mKmbs5p00U6M0ptW0e367UwqVWzmSx7tbz5Kply0drY5FJJ3wFmZVDN5CsgQeajr8jUph7zyJHrZdHBwI/JWcpFlPNX5f9ZXf0jItYoC/U2pFK1pC5JOzK1cdfpEXH8KPs3Js8hA+rWDNSHI+LIHo+f8xxU23JpWR7x62A2fPi/MSKurd4haYOabeda2bA1yv8bAZszVUpwB3LToF6+Q/69FtGhZjOzPHBoaPWIuECaNgA5o5srDWKWnEMOBI4BHizpv8ldBv9rsl0aj4g4EDhQ0pcj4m2T7s+gJL2JXFj6cOBictvuc4Hn1Wi7L3ku+Xa5a89SHvV9PZrNBvcn87mvIX/u9coC02U2RcLpH2Y2dq1p6rb7FkXEZjXafgI4d66VDZN0MrBTRCwut9cgd4Fb3hbI1qLcdfOd5O9oU0k7kxdjy82s0jBKhZnnkRdgP52j5SeXeWXGcHPg/IjYpPzdPhoRfctsSroU2CQi/lVurwj8YranK0r6NbBvRHxd0mrkJl4LoseusnOdR6rNbGzKB8cTgLXaqmGsSf0p0D2BD0iaa7mI88mFRS13k3nhtczR6d4m3gEcAjxW0u/JFKHdJtul2S8irgKumnQ/rK+7IuIuSUhaJSKukrTRAO3XBlp542v1euAssg3wHEkfLtVp9mOAc+Bc5KDazMZpIzKdYW0y/aFlMbn4sK+muYgTdARwgaRjyNSNl5E7m/XVZbr3mRHx/rH0dILactBPBE4jF7P+DdgJqLM5htlsd4Oktcl6+6dIuhW4sU+blk8CF0k6nRxUeDYwF84F76dUpwE+Rp739yfPbcskp3+Y2ViVqcr3RsQn+z64c/uOuYgR0TcXcdJK1ZNnlZtnRsQvarabk9O9w5DU2rSjlYN+LBk47ED+zt40qb6ZjYOk55CjzT+OiLtrPP4I4DfkLvR7K9wAAAW+SURBVLi/BX4eEX8cby+bW56q07R4pNrMxioi7pH0fHK0ZRh7MpWLuFUrF3FkHRyxVgWPMrp+XfnX+t4DBij9NRenewcWER+Fe3PQN63koO8DHDXBrpmNRUScMWCTw4AtgR3JxcoXSzozIg4YeedGa3mqTgM4qDazmXGupC8C3yOn9QGIiItqtG2aizjTviNpB+AWKgE1g5X++hS5tfBpzK3p3iYa5aCbLavKDq1nkIMLWwFvJdeqzPagermpTtPi9A8zG7sSHLaLiNi6RttjgN2BvcjcvFuBlSNi29H2crQ6VTwZsP1Dmco9vGAuTPc2IemDZO3yag769yLiUxPtmNmESfopuXHMeWTN/rMj4qbJ9qqe5a06jYNqM5szBs1FnKQyMn94RFw4ZPuXk1O+QX6IHjPK/s1Gw+agmy3LJH0e2IzctOscst79eRFx50Q7ZktxUG1mY1e2l/8IUyXizgA+VnbIXCaVbZUfA1xPprzU3sFS0peARwOt3cdeBVwTEe8YU3fNbJaTdD9y1u4/gXUiYpUJd8naOKg2s7GTdDRwOXB4ues1wMYR8fLureY2Set1ur/OTnySrgCe2Np5TNIKwGUR8YTR9tLMZjtJ7yRncDYjL9LPBM6KiJ9NtGO2FC9UNLOZ8KiI2Kly+6OSLp5Yb2ZAw22sf0Uu3Gs9xyOASxt3yszmotXIeu2LImLJpDtj3TmoNrOZcKekLSPibABJzwScD9jdA4ErJV1Qbm8OnCfpOICI2HFiPTOzGRURn510H6weB9VmNhPeCnyz5FZDVvB43QT7M9t9eNIdMDOzwTin2szGRtKeEXFA2WL7HElrAkTEHZPu22wnaR1gC7L6x4XLekk9M7O5boVJd8DMlmm7l/8PggymHVD3V7ZmvwB4OblhwvmS3jDZXpmZWS8eqTazsZF0JPB0YB5wTfVb1CwvtzyS9CvgGRHx53L7gcC5ETGbd5I0M1uuOafazMYmInYtaQw/Aby4rr4bgMWV24uB302oL2ZmVoNHqs3MZhlJ3wSeBBxL5lS/hEwH+TVARHxucr0zM7NOPFJtZmNXSujtA6xHnnda6R+PnGS/ZrFrmJ4uc2z5f40J9MXMzGrwSLWZjZ2kq4D/BywC7mnd38oZNjMzm+s8Um1mM+H2iDhp0p2YKyTNA94DPAFYtXV/RGw9sU6ZmVlPLqlnZjPhNEmflfR0SZu2/k26U7PYt4GrgA2AjwLXARdOskNmZtab0z/MbOwknVa+bJ1wWjnVHnntQNKiiNhM0qWtsoOSzoiI50y6b2Zm1pnTP8xsJpze4T5f0Xf3z/L/HyRtB9wIPHyC/TEzsz4cVJvZTPhr5etVge2BKyfUl7ngE5LWAv6D3I1yTXKhp5mZzVJO/zCzGSdpFeC4iHjhpPtiZmY2Cl6oaGaTsDrgGtVdSPqMpDUlrSzpp5JukfTqSffLzMy6c1BtZmMn6TJJl5Z/VwC/Ag6YdL9msRdExB1kmswNwGOAvSfbJTMz68U51WY2E7avfL0E+FNELJlUZ+aAlcv/2wJHRsRfJE2yP2Zm1oeDajMbu4i4ftJ9mGN+VHahvBN4e9kM5q4J98nMzHrwQkUzs1lI0v2BOyLiHkmrA2tGxB8n3S8zM+vMI9VmZrOEpK0j4meSXl65r/qQH858r8zMrA4H1WZms8ezgZ8BO5Cb46jtfwfVZmazlINqM7PZY7GkdwOXMxVMg3efNDOb9RxUm5nNHvcr/28EbA4cSwbWOwBnTqpTZmbWnxcqmpnNMpJOBnaKiMXl9hrAURHxosn2zMzMuvHmL2Zms8984O7K7buB9SfTFTMzq8PpH2Zms88RwAWSjiHzqV8GHD7ZLpmZWS9O/zAzm4UkbQo8q9w8MyJ+Mcn+mJlZbw6qzczMzMwack61mZmZmVlDDqrNzMzMzBpyUG1mZmZm1pCDajMzMzOzhhxUm5mZmZk19P8Bh2IV6ST/uFEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[12,4])\n",
    "plt.bar(range(40),w[np.r_[indexer[:20],indexer[-20:]]])\n",
    "plt.xticks(range(40), np.r_[fn[indexer[:20]], fn[indexer[-20:]]], rotation=90, ha='left')\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
